{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from keybert import KeyBERT\n",
    "import yfinance as yf\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "news_raw = pd.read_csv(\"C:/projectnasdaq/news_raw.csv\", encoding='latin1') # 뉴스 raw data\n",
    "nasdaq_stock = pd.read_csv(\"C:/projectnasdaq/nasdaq_stocks.csv\", encoding='latin1') # stock_list data\n",
    "rep_stock = pd.read_csv(\"C:/projectnasdaq/nasdaq_stocks_refine_total.csv\", encoding='latin1') # 대표단어 csv\n",
    "\n",
    "# 테스트 용도로 데이터 1000개만 가지고\n",
    "news_raw = news_raw.head(1000)\n",
    "news_raw = news_raw[['news_id','title','summary']]\n",
    "nasdaq_stock = nasdaq_stock[['pk','symbol','name']]\n",
    "rep_stock = rep_stock[['pk','symbol','name','name_a']]\n",
    "\n",
    "# new_raw 데이터 전처리\n",
    "news_raw['summary'] = news_raw['summary'].str.lower() #소문자화\n",
    "news_raw['summary'] = news_raw['summary'].apply(lambda x: re.sub('[^a-zA-Z\\d&]', ' ', str(x)).strip())\n",
    "self_stop_words = {'bloomberg'}\n",
    "news_raw['summary'].replace(self_stop_words, '', regex=True, inplace=True)\n",
    "\n",
    "# news_raw 데이터 토큰화\n",
    "news_raw['tokenize'] = 0\n",
    "news_raw['tokenize'] = news_raw['summary'].str.split(\" \")\n",
    "news_raw['tokenize'] = news_raw['tokenize'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "news_raw['company_name'] = 0\n",
    "news_raw['keyword'] = 0 # keybert로 뽑아낸 키워드 컬럼\n",
    "news_raw['keyword2'] = 0\n",
    "\n",
    "# list에 담아주기\n",
    "tokenize_list = news_raw['tokenize']\n",
    "rep_list = rep_stock['name_a'].str.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 회사 이름 추출 => 추출 완료 ( company_word.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 회사이름 추출 데이터 저장용도\n",
    "company_word = pd.DataFrame(columns=['news_id', 'company_word','pk'])\n",
    "\n",
    "# 대표단어 csv파일에서 대표단어가 포함되면 맵핑\n",
    "i = 0\n",
    "\n",
    "for token_num, token in enumerate(tokenize_list):  # news_raw data 토큰화\n",
    "    for rep_num, rep in enumerate(rep_list):  # 대표단어 csv파일에서 대표단어에 해당\n",
    "        i = i + 1\n",
    "        if len(rep) == 1:\n",
    "            if rep[0] in token:\n",
    "                company_word.loc[i] = [news_raw['news_id'][token_num], rep[0], rep_stock['pk'][rep_num]]\n",
    "\n",
    "        elif len(rep) == 2:  # 대표단어가 2개로 된 단어일 때\n",
    "            if rep[0] in token:  # 대표단어의 첫번째 단어가 org단어에 있으면\n",
    "                found = token.index(rep[0])  # 대표단어의 첫번째 단어와 일치하는 org단어의 인덱스 위치 번호\n",
    "                try:\n",
    "                    search = found + 1  # stocklist의 첫번째 단어가 org에 포함됐을때 그 다음 단어\n",
    "                    search_found = token[search]  # org의 (+1을 한) 다음 단어에 해당\n",
    "                    if rep[1] == search_found:\n",
    "                        company_word.loc[i] = [news_raw['news_id'][token_num], rep[0] + \" \" + rep[1],\n",
    "                                                 rep_stock['pk'][rep_num]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "        elif len(rep) == 3:\n",
    "            if rep[0] in token:\n",
    "                try:\n",
    "                    search_found = token[token.index(rep[0]) + 1]\n",
    "                    if rep[1] == search_found:\n",
    "                        two_found = token[token.index(rep[0]) + 2]\n",
    "                        if rep[2] == two_found:\n",
    "                            company_word.loc[i] = [news_raw['news_id'][token_num],\n",
    "                                                     rep[0] + \" \" + rep[1] + \" \" + rep[2], rep_stock['pk'][rep_num]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "company_word = pd.merge(company_word, nasdaq_stock, how='left', left_on='pk', right_on='pk')\n",
    "#company_word = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 뉴스 원문에서 키워드 추출 ( Keybert 사용 )=> 추출 완료 ( keyword.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keybert로 키워드 추출 ( 키워드 1단어들, 2단어들 )\n",
    "summaries = news_raw['summary']\n",
    "# 뉴스 원문 키워드 10개 추출 저장 컬럼\n",
    "news_raw['news_ten_keyword'] = 0\n",
    "\n",
    "for sum_num, summary in enumerate(summaries):\n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(summary,top_n=5)\n",
    "    news_raw['keyword'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 1)) # 뉴스 원문 키워드 한 단어들 다섯개 추출\n",
    "    news_raw['keyword2'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 2)) # 뉴스 원문 키워드 두 단어들 다섯개 추출\n",
    "    news_raw['ten_keyword'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 1),top_n= 10) # 뉴스 원문 키워드 10개 추출\n",
    "#news_raw.to_csv('C:/projectnasdaq/project2/keyword.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 종목 정보 수집 ( yfinance 패키지 사용 ) => 수집완료"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 종목코드 리스트\n",
    "stocks = nasdaq_stock['symbol']\n",
    "# 종목코드에 대한 정보 수집용 데이터프레임 생성\n",
    "stock_info = pd.DataFrame(columns=['symbol', 'info'])\n",
    "i = 0\n",
    "\n",
    "for stock_num, stock in enumerate(stocks):\n",
    "    tickers = yf.Ticker(stock)\n",
    "    ticker = tickers.info\n",
    "    i = i + 1\n",
    "    #print(stock_num,stock, \"===>>\",ticker)\n",
    "    stock_info.loc[i] = [stock, ticker]\n",
    "    time.sleep(random.uniform(3, 4))\n",
    "\n",
    "#stock_info.to_csv('C:/projectnasdaq/project2/stock_info.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 추출된 회사 이름이랑 ( 전처리 한 ) 키워드 연결 ( company_and_keyword.csv 파일에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "company_word = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')\n",
    "keyword = pd.read_csv('C:/projectnasdaq/project2/keyword.csv')\n",
    "\n",
    "# 키워드 전처리\n",
    "keyword['keyword'] = keyword['keyword'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())  # 정규식전처리\n",
    "keyword['keyword'] = keyword['keyword'].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip())  # 공백 여러개 하나로\n",
    "keyword['keyword'] = keyword['keyword'].str.split(\" \")\n",
    "\n",
    "keyword['news_keyword_ten'] = keyword['news_keyword_ten'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())  # 정규식전처리\n",
    "keyword['news_keyword_ten'] = keyword['news_keyword_ten'].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip())  # 공백 여러개 하나로\n",
    "keyword['news_keyword_ten'] = keyword['news_keyword_ten'].str.split(\" \")\n",
    "\n",
    "keyword['keyword2'] = keyword['keyword2'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())\n",
    "keyword['keyword2'] = keyword['keyword2'].str.split(\"  \")\n",
    "\n",
    "\n",
    "# 공백으로 토큰화되거나 비어있는 내용으로 토큰화 되어있으면 지우기\n",
    "keyword['keyword2'] = keyword['keyword2'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "company_word[['keyword', 'keyword2','news_keyword_ten']] = 0\n",
    "\n",
    "keyword_list1 = keyword['keyword']\n",
    "keyword_list2 = keyword['keyword2']\n",
    "\n",
    "keyword_id = keyword['news_id']\n",
    "company_id = company_word['news_id']\n",
    "\n",
    "for i, j in enumerate(company_id):\n",
    "    for k, l in enumerate(keyword_id):\n",
    "        if j == l:\n",
    "            company_word['keyword'][i] = keyword['keyword'][k]\n",
    "            company_word['keyword2'][i] = keyword['keyword2'][k]\n",
    "\n",
    "#company_mapping.to_csv('C:/projectnasdaq/project2/company_and_keyword.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## yahoo_dataset 파일 수정 ( yahoo_dataset_mapping.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# yahoo_dataset 파일 수정 ( -> symbol name 수정 )\n",
    "yahoo_dataset = pd.read_csv('C:/projectnasdaq/project2/yahoo_dataset.csv')\n",
    "# yahoo_dataset에서 필요없는 컬럼들 지우고 csv 파일에 있는 종목코드에 종목명 데이터들 붙임\n",
    "\n",
    "yahoo_dataset.insert(1,'new_symbol','0')\n",
    "yahoo_dataset.insert(2,'name','0')\n",
    "yahoo_dataset.insert(3,'company_word','0')\n",
    "\n",
    "yahoo_dataset_symbol = yahoo_dataset['symbol']\n",
    "rep_stock_symbol = rep_stock['symbol']\n",
    "\n",
    "for i, j in enumerate(yahoo_dataset_symbol):\n",
    "    for k, l in enumerate(rep_stock_symbol):\n",
    "        if j == l:\n",
    "            yahoo_dataset['new_symbol'][i] = rep_stock['symbol'][k]\n",
    "            yahoo_dataset['name'][i] = rep_stock['name'][k]\n",
    "            yahoo_dataset['company_word'][i] = rep_stock['name_a'][k]\n",
    "            break\n",
    "\n",
    "# yahoo_dataset 컬럼 정리\n",
    "yahoo_dataset.drop(columns=[\"quoteType\", \"currency\", 'regularMarketPrice', 'regularMarketChange', 'regularMarketChangePercent',\n",
    "             'regularMarketVolume', 'averageDailyVolume3Month', 'marketCap', 'trailingPE', 'fiftyTwoWeekLow',\n",
    "             'fiftyTwoWeekHigh', 'regularMarketOpen', 'priceHint', 'underlyingSymbol'], inplace=True)\n",
    "#yahoo_dataset.to_csv('C:/projectnasdaq/project2/yahoo_dataset_mapping.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 종목명이 추출된 뉴스 키워드들끼리 모으기 ( 딕셔너리 형태로 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# company단어들 하나씩만 list에 담기 -> 단어 이름이 같은 종목명들의 키워드 모으기 위해서\n",
    "company_and_keyword = pd.read_csv('C:/projectnasdaq/project2/company_and_keyword.csv')\n",
    "company_and_keyword.drop(columns=[\"Unnamed: 0\", 'Unnamed: 0.1'], inplace=True)\n",
    "company_word = company_and_keyword['company_word']\n",
    "\n",
    "company_word_same_list = []\n",
    "for company in company_word:\n",
    "    if company not in company_word_same_list:\n",
    "        company_word_same_list.append(company)\n",
    "\n",
    "company_word_sames = pd.DataFrame(company_word_same_list, columns=['company_word_same'])\n",
    "company_word_same = company_word_sames['company_word_same']\n",
    "\n",
    "# 키워드랑 company_name이랑 데이터프레임에서 맵핑 시키기위한 새로운 dataframe 생성\n",
    "company_name_keyword_organize = pd.DataFrame(columns=['company', 'keyword', 'keyword2','key_list'])\n",
    "\n",
    "# 딕셔너리를 { news_id : keyword } 형태로 만들기 위해서 index를 news_id로 설정\n",
    "company_and_keyword = company_and_keyword.set_index(keys='news_id', drop=False, inplace=False)\n",
    "\n",
    "# company_name에 대한 키워드들 딕셔너리 형태로 모으기\n",
    "for i, j in enumerate(company_word_same):\n",
    "    company_name_keyword_organize.loc[i] = [j, company_and_keyword[company_and_keyword['company_word'] == j]['keyword'].to_dict(), company_and_keyword[company_and_keyword['company_word'] == j]['keyword2'].to_dict(),company_and_keyword[company_and_keyword['company_word'] == j]['keyword'].tolist()] # 리스트 형태로 키워드만 뽑아오기 위해서"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## news_raw_dataset 만들기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# company_name_keyword_organize.csv에 column 삽입\n",
    "company_name_keyword_organize.insert(0, 'symbol','0')\n",
    "company_name_keyword_organize.insert(1, 'name','0')\n",
    "company_name_keyword_organize.insert(2, 'shortName','0')\n",
    "company_name_keyword_organize.insert(3, 'longName','0')\n",
    "company_name_keyword_organize.insert(5, 'company_info','0')\n",
    "\n",
    "yahoo_dataset_mapping = pd.read_csv('C:/projectnasdaq/project2/yahoo_dataset_mapping.csv')\n",
    "company_word_csv = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')\n",
    "\n",
    "# company_name_keyword_organize.csv에 symbol, name 데이터 삽입\n",
    "company_word = company_word_csv['company_word']\n",
    "company = company_name_keyword_organize['company']\n",
    "\n",
    "for i,j in enumerate(company_word):\n",
    "    for k, l in enumerate(company):\n",
    "        if j==l:\n",
    "            company_name_keyword_organize['symbol'][k] = company_word_csv['symbol'][i]\n",
    "            company_name_keyword_organize['name'][k] = company_word_csv['name'][i]\n",
    "            break\n",
    "\n",
    "# company__name.csv에 yahoo finance 정보 수집 내용 삽입\n",
    "yahoo_dataset_mapping_symbol = yahoo_dataset_mapping['new_symbol']\n",
    "company_name_keyword_organize_symbol = company_name_keyword_organize['symbol']\n",
    "\n",
    "for i,j in enumerate(yahoo_dataset_mapping_symbol):\n",
    "    for k,l in enumerate(company_name_keyword_organize_symbol):\n",
    "        if j==l:\n",
    "            company_name_keyword_organize['shortName'][k] = yahoo_dataset_mapping['shortName'][i]\n",
    "            company_name_keyword_organize['longName'][k] = yahoo_dataset_mapping['longName'][i]\n",
    "            company_name_keyword_organize['company_info'][k] = yahoo_dataset_mapping['company_info'][i]\n",
    "            break\n",
    "\n",
    "# 대표 키워드 추출하기\n",
    "# 키워드 빈도수 순으로 정리해서 5개까지만 뽑아오기\n",
    "company_name_keyword_organize['frequency'] = 0\n",
    "company_name_keyword_organize\n",
    "\n",
    "key_list_ = company_name_keyword_organize['key_list']\n",
    "for i, j in enumerate(key_list_):\n",
    "        company_name_keyword_organize['key_list'][i] = ''.join(j)\n",
    "\n",
    "company_name_keyword_organize['key_list'].replace(['\\]','\\[','\\''],'',regex=True, inplace=True)\n",
    "company_name_keyword_organize['key_list'].replace(',',' ',regex=True, inplace=True)\n",
    "company_name_keyword_organize['key_list'] = company_name_keyword_organize['key_list'].str.split(\" \")\n",
    "company_name_keyword_organize['key_list'] = company_name_keyword_organize['key_list']\\\n",
    "    .apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "\n",
    "frequency_word = company_name_keyword_organize['key_list']\n",
    "for i, j in enumerate(frequency_word):\n",
    "    # 대표 키워드 빈도순으로 5개 추출\n",
    "    company_name_keyword_organize['frequency'][i] = Counter(j).most_common(5)\n",
    "# 다섯개 뽑아온 키워드 전처리\n",
    "company_name_keyword_organize['frequency'] = company_name_keyword_organize['frequency']\\\n",
    "    .apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())\n",
    "company_name_keyword_organize['frequency'] = company_name_keyword_organize['frequency'].str.split(\" \")\n",
    "company_name_keyword_organize['frequency'] = company_name_keyword_organize['frequency']\\\n",
    "    .apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "# 완성된 news_raw dataset\n",
    "#company__name.to_csv('C:/projectnasdaq/project2/news_raw_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 맵핑 (1) 뉴스 원문에 종목명의 대표 키워드가 포함될 때"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 맵핑 수 : 543\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 원문에 대표 키워드가 포함될 경우 news_id와 symbol 맵핑\n",
    "frequency = company_name_keyword_organize['frequency'] # 키워드 빈도수로 정렬 후 5개만 담아온 리스트\n",
    "news_stock_mapping = pd.DataFrame(columns=['news_id', 'symbol','name','summary','frequency'])\n",
    "\n",
    "a = 0\n",
    "for i, j in enumerate(tokenize_list):\n",
    "    for k,l in enumerate(frequency):\n",
    "        a = a + 1\n",
    "        #print(news_raw['news_id'][i])\n",
    "        together = set(j)&set(l)\n",
    "        # 뉴스 원문에 대표 키워드가 4개 이상 교집합으로 있을 경우\n",
    "        if len(together)==5:\n",
    "            news_stock_mapping.loc[a] = [news_raw['news_id'][i], company_name_keyword_organize['symbol'][k], company_name_keyword_organize['name'][k],news_raw['summary'][i], company_name_keyword_organize['frequency'][k]]\n",
    "\n",
    "print('총 맵핑 수 :',len(news_stock_mapping))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 맵핑(2) 뉴스 원문 키워드(10개)랑 종목명의 대표 키워드가 일치할 때"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 맵핑 수 : 1099\n"
     ]
    }
   ],
   "source": [
    "news_stock_mapping_2 = pd.DataFrame(columns=['news_id', 'symbol','name','summary','frequency','news_keyword_ten'])\n",
    "news_raw_keyword_ten = company_name_keyword_organize['frequency']\n",
    "# frequency => 종목명의 대표키워드\n",
    "a=0\n",
    "for i,j in enumerate(news_raw_keyword_ten):\n",
    "    for k,l in enumerate(frequency):\n",
    "        a=a+1\n",
    "        together = set(j)&set(l)\n",
    "        if len(together)>=4:\n",
    "            news_stock_mapping_2.loc[a] = [keyword['news_id'][i], company_name_keyword_organize['symbol'][k], company_name_keyword_organize['name'][k],keyword['summary'][i], company_name_keyword_organize['frequency'][k],keyword['news_keyword_ten'][i]]\n",
    "\n",
    "print('총 맵핑 수 :',len(news_stock_mapping_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}