{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from keybert import KeyBERT\n",
    "import yfinance as yf\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "news_raw = pd.read_csv(\"C:/projectnasdaq/news_raw.csv\", encoding='latin1') # 뉴스 raw data\n",
    "nasdaq_stock = pd.read_csv(\"C:/projectnasdaq/nasdaq_stocks.csv\", encoding='latin1') # stock_list data\n",
    "rep_stock = pd.read_csv(\"C:/projectnasdaq/nasdaq_stocks_refine_total.csv\", encoding='latin1') # 대표단어 csv\n",
    "\n",
    "# 테스트 용도로 데이터 1000개만 가지고\n",
    "news_raw = news_raw.head(1000)\n",
    "news_raw = news_raw[['news_id','title','summary']]\n",
    "nasdaq_stock = nasdaq_stock[['pk','symbol','name']]\n",
    "rep_stock = rep_stock[['pk','symbol','name','name_a']]\n",
    "\n",
    "# new_raw 데이터 전처리\n",
    "news_raw['summary'] = news_raw['summary'].str.lower() #소문자화\n",
    "news_raw['summary'] = news_raw['summary'].apply(lambda x: re.sub('[^a-zA-Z\\d&]', ' ', str(x)).strip())\n",
    "self_stop_words = {'bloomberg'}\n",
    "news_raw['summary'].replace(self_stop_words, '', regex=True, inplace=True)\n",
    "\n",
    "# news_raw 데이터 토큰화\n",
    "news_raw['tokenize'] = 0\n",
    "news_raw['tokenize'] = news_raw['summary'].str.split(\" \")\n",
    "news_raw['tokenize'] = news_raw['tokenize'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "news_raw['company_name'] = 0\n",
    "news_raw['keyword'] = 0 # keybert로 뽑아낸 키워드 컬럼\n",
    "news_raw['keyword2'] = 0\n",
    "\n",
    "# list에 담아주기\n",
    "tokenize_list = news_raw['tokenize']\n",
    "rep_list = rep_stock['name_a'].str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0 news_id                                              title  \\\n0             0  345585  Nestle Outshines Rivals With Revenue Growth Le...   \n1             1  345586  Total Makes Surprise Profit as Trading Gains O...   \n2             2  345590  Airbus Follows Boeing in Paring Output to Weat...   \n3             3  345591  Virus Uptick Imperils South Europe's Nascent T...   \n4             4  345595  PG&E Fire Insurance Costs Skyrocket After Bank...   \n...         ...     ...                                                ...   \n997         995  443773  Localiza to Form $9 Billion Car-Rental Giant W...   \n998         996  443778  Mendoza Province Is First to Restructure After...   \n999         997  443779  Manufacturing Keeps German Economy on a Recove...   \n1000        998  443780  ECB Must Limit Emergency Powers to Temporary C...   \n1001        999  443781  Citi Pledges to Become Antiracist, Review Inte...   \n\n                                                summary  \\\n0          nestle sa sailed past ailing consumer goo...   \n1          total se made a surprise profit after  ve...   \n2          airbus se cut back wide body jet producti...   \n3          nadine scheiner s efforts to travel from ...   \n4          pg&e corp  is finding it very costly to b...   \n...                                                 ...   \n997        localiza rent a car sa and unidas  two of...   \n998        argentina s mendoza province has reached ...   \n999        german factories kept europe s biggest ec...   \n1000       the european central bank risks legal tro...   \n1001       citigroup inc  will spend  1 billion over...   \n\n                                               tokenize company_name  \\\n0     ['nestle', 'sa', 'sailed', 'past', 'ailing', '...            0   \n1     ['total', 'se', 'made', 'a', 'surprise', 'prof...            0   \n2     ['airbus', 'se', 'cut', 'back', 'wide', 'body'...            0   \n3     ['nadine', 'scheiner', 's', 'efforts', 'to', '...            0   \n4     ['pg&e', 'corp', 'is', 'finding', 'it', 'very'...            0   \n...                                                 ...          ...   \n997   ['localiza', 'rent', 'a', 'car', 'sa', 'and', ...            0   \n998   ['argentina', 's', 'mendoza', 'province', 'has...            0   \n999   ['german', 'factories', 'kept', 'europe', 's',...            0   \n1000  ['the', 'european', 'central', 'bank', 'risks'...            0   \n1001  ['citigroup', 'inc', 'will', 'spend', '1', 'bi...            0   \n\n                                                keyword  \\\n0          [nestle, starbucks, brands, bottled, market]   \n1            [profit, earnings, markets, market, slump]   \n2        [airbus, boeing, a, restructuring, planemaker]   \n3     [spain, catalonia, barcelona, coronavirus, costa]   \n4         [insurance, pg, wildfires, wildfire, damages]   \n...                                                 ...   \n997        [brazilian, janeiro, brasil, unidas, brazil]   \n998       [buenos, argentina, mendoza, aires, province]   \n999      [economy, frankfurt, euro, germany, factories]   \n1000               [ecb, pandemic, euro, mersch, risks]   \n1001          [citibank, racial, citigroup, citi, race]   \n\n                                               keyword2  \\\n0     [nestle sa, nestle, underperforming brands, br...   \n1     [market crisis, outperformance trading, compan...   \n2     [airbus rely, pandemic airbus, airbus making, ...   \n3     [coronavirus spain, spain tourism, trips spain...   \n4     [wildfire insurance, insurance wildfires, insu...   \n...                                                 ...   \n997   [brazil antitrust, companies brazil, localiza ...   \n998   [province bonds, argentina investors, mendoza ...   \n999   [german industry, german factories, economy mo...   \n1000  [ecb legal, bankers mersch, mersch ecb, bank r...   \n1001  [racial wealth, black executives,  finance bla...   \n\n                                            keyword_ten Unnamed: 9  ...  \\\n0     [nestle, starbucks, brands, bottled, market, n...        NaN  ...   \n1     [profit, earnings, markets, market, slump, tra...        NaN  ...   \n2     [airbus, boeing, a, restructuring, planemaker,...        NaN  ...   \n3     [spain, catalonia, barcelona, coronavirus, cos...        NaN  ...   \n4     [insurance, pg, wildfires, wildfire, damages, ...        NaN  ...   \n...                                                 ...        ...  ...   \n997   [brazilian, janeiro, brasil, unidas, brazil, l...        NaN  ...   \n998   [buenos, argentina, mendoza, aires, province, ...        NaN  ...   \n999   [economy, frankfurt, euro, germany, factories,...        NaN  ...   \n1000  [ecb, pandemic, euro, mersch, risks, bankers, ...        NaN  ...   \n1001  [citibank, racial, citigroup, citi, race, raci...        NaN  ...   \n\n     Unnamed: 177 Unnamed: 178 Unnamed: 179 Unnamed: 180 Unnamed: 181  \\\n0             NaN          NaN          NaN          NaN          NaN   \n1             NaN          NaN          NaN          NaN          NaN   \n2             NaN          NaN          NaN          NaN          NaN   \n3             NaN          NaN          NaN          NaN          NaN   \n4             NaN          NaN          NaN          NaN          NaN   \n...           ...          ...          ...          ...          ...   \n997           NaN          NaN          NaN          NaN          NaN   \n998           NaN          NaN          NaN          NaN          NaN   \n999           NaN          NaN          NaN          NaN          NaN   \n1000          NaN          NaN          NaN          NaN          NaN   \n1001          NaN          NaN          NaN          NaN          NaN   \n\n     Unnamed: 182 Unnamed: 183 Unnamed: 184 Unnamed: 185 Unnamed: 186  \n0             NaN          NaN          NaN          NaN          NaN  \n1             NaN          NaN          NaN          NaN          NaN  \n2             NaN          NaN          NaN          NaN          NaN  \n3             NaN          NaN          NaN          NaN          NaN  \n4             NaN          NaN          NaN          NaN          NaN  \n...           ...          ...          ...          ...          ...  \n997           NaN          NaN          NaN          NaN          NaN  \n998           NaN          NaN          NaN          NaN          NaN  \n999           NaN          NaN          NaN          NaN          NaN  \n1000          NaN          NaN          NaN          NaN          NaN  \n1001          NaN          NaN          NaN          NaN          NaN  \n\n[1002 rows x 187 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>news_id</th>\n      <th>title</th>\n      <th>summary</th>\n      <th>tokenize</th>\n      <th>company_name</th>\n      <th>keyword</th>\n      <th>keyword2</th>\n      <th>keyword_ten</th>\n      <th>Unnamed: 9</th>\n      <th>...</th>\n      <th>Unnamed: 177</th>\n      <th>Unnamed: 178</th>\n      <th>Unnamed: 179</th>\n      <th>Unnamed: 180</th>\n      <th>Unnamed: 181</th>\n      <th>Unnamed: 182</th>\n      <th>Unnamed: 183</th>\n      <th>Unnamed: 184</th>\n      <th>Unnamed: 185</th>\n      <th>Unnamed: 186</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>345585</td>\n      <td>Nestle Outshines Rivals With Revenue Growth Le...</td>\n      <td>nestle sa sailed past ailing consumer goo...</td>\n      <td>['nestle', 'sa', 'sailed', 'past', 'ailing', '...</td>\n      <td>0</td>\n      <td>[nestle, starbucks, brands, bottled, market]</td>\n      <td>[nestle sa, nestle, underperforming brands, br...</td>\n      <td>[nestle, starbucks, brands, bottled, market, n...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>345586</td>\n      <td>Total Makes Surprise Profit as Trading Gains O...</td>\n      <td>total se made a surprise profit after  ve...</td>\n      <td>['total', 'se', 'made', 'a', 'surprise', 'prof...</td>\n      <td>0</td>\n      <td>[profit, earnings, markets, market, slump]</td>\n      <td>[market crisis, outperformance trading, compan...</td>\n      <td>[profit, earnings, markets, market, slump, tra...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>345590</td>\n      <td>Airbus Follows Boeing in Paring Output to Weat...</td>\n      <td>airbus se cut back wide body jet producti...</td>\n      <td>['airbus', 'se', 'cut', 'back', 'wide', 'body'...</td>\n      <td>0</td>\n      <td>[airbus, boeing, a, restructuring, planemaker]</td>\n      <td>[airbus rely, pandemic airbus, airbus making, ...</td>\n      <td>[airbus, boeing, a, restructuring, planemaker,...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>345591</td>\n      <td>Virus Uptick Imperils South Europe's Nascent T...</td>\n      <td>nadine scheiner s efforts to travel from ...</td>\n      <td>['nadine', 'scheiner', 's', 'efforts', 'to', '...</td>\n      <td>0</td>\n      <td>[spain, catalonia, barcelona, coronavirus, costa]</td>\n      <td>[coronavirus spain, spain tourism, trips spain...</td>\n      <td>[spain, catalonia, barcelona, coronavirus, cos...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>345595</td>\n      <td>PG&amp;E Fire Insurance Costs Skyrocket After Bank...</td>\n      <td>pg&amp;e corp  is finding it very costly to b...</td>\n      <td>['pg&amp;e', 'corp', 'is', 'finding', 'it', 'very'...</td>\n      <td>0</td>\n      <td>[insurance, pg, wildfires, wildfire, damages]</td>\n      <td>[wildfire insurance, insurance wildfires, insu...</td>\n      <td>[insurance, pg, wildfires, wildfire, damages, ...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>995</td>\n      <td>443773</td>\n      <td>Localiza to Form $9 Billion Car-Rental Giant W...</td>\n      <td>localiza rent a car sa and unidas  two of...</td>\n      <td>['localiza', 'rent', 'a', 'car', 'sa', 'and', ...</td>\n      <td>0</td>\n      <td>[brazilian, janeiro, brasil, unidas, brazil]</td>\n      <td>[brazil antitrust, companies brazil, localiza ...</td>\n      <td>[brazilian, janeiro, brasil, unidas, brazil, l...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>996</td>\n      <td>443778</td>\n      <td>Mendoza Province Is First to Restructure After...</td>\n      <td>argentina s mendoza province has reached ...</td>\n      <td>['argentina', 's', 'mendoza', 'province', 'has...</td>\n      <td>0</td>\n      <td>[buenos, argentina, mendoza, aires, province]</td>\n      <td>[province bonds, argentina investors, mendoza ...</td>\n      <td>[buenos, argentina, mendoza, aires, province, ...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>997</td>\n      <td>443779</td>\n      <td>Manufacturing Keeps German Economy on a Recove...</td>\n      <td>german factories kept europe s biggest ec...</td>\n      <td>['german', 'factories', 'kept', 'europe', 's',...</td>\n      <td>0</td>\n      <td>[economy, frankfurt, euro, germany, factories]</td>\n      <td>[german industry, german factories, economy mo...</td>\n      <td>[economy, frankfurt, euro, germany, factories,...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <td>998</td>\n      <td>443780</td>\n      <td>ECB Must Limit Emergency Powers to Temporary C...</td>\n      <td>the european central bank risks legal tro...</td>\n      <td>['the', 'european', 'central', 'bank', 'risks'...</td>\n      <td>0</td>\n      <td>[ecb, pandemic, euro, mersch, risks]</td>\n      <td>[ecb legal, bankers mersch, mersch ecb, bank r...</td>\n      <td>[ecb, pandemic, euro, mersch, risks, bankers, ...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>999</td>\n      <td>443781</td>\n      <td>Citi Pledges to Become Antiracist, Review Inte...</td>\n      <td>citigroup inc  will spend  1 billion over...</td>\n      <td>['citigroup', 'inc', 'will', 'spend', '1', 'bi...</td>\n      <td>0</td>\n      <td>[citibank, racial, citigroup, citi, race]</td>\n      <td>[racial wealth, black executives,  finance bla...</td>\n      <td>[citibank, racial, citigroup, citi, race, raci...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1002 rows × 187 columns</p>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 회사 이름 추출 => 추출 완료 ( company_word.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 회사이름 추출 데이터 저장용도\n",
    "company_word = pd.DataFrame(columns=['news_id', 'company_word','pk'])\n",
    "\n",
    "# 대표단어 csv파일에서 대표단어가 포함되면 맵핑\n",
    "i = 0\n",
    "\n",
    "for token_num, token in enumerate(tokenize_list):  # news_raw data 토큰화\n",
    "    for rep_num, rep in enumerate(rep_list):  # 대표단어 csv파일에서 대표단어에 해당\n",
    "        i = i + 1\n",
    "        if len(rep) == 1:\n",
    "            if rep[0] in token:\n",
    "                company_word.loc[i] = [news_raw['news_id'][token_num], rep[0], rep_stock['pk'][rep_num]]\n",
    "\n",
    "        elif len(rep) == 2:  # 대표단어가 2개로 된 단어일 때\n",
    "            if rep[0] in token:  # 대표단어의 첫번째 단어가 org단어에 있으면\n",
    "                found = token.index(rep[0])  # 대표단어의 첫번째 단어와 일치하는 org단어의 인덱스 위치 번호\n",
    "                try:\n",
    "                    search = found + 1  # stocklist의 첫번째 단어가 org에 포함됐을때 그 다음 단어\n",
    "                    search_found = token[search]  # org의 (+1을 한) 다음 단어에 해당\n",
    "                    if rep[1] == search_found:\n",
    "                        company_word.loc[i] = [news_raw['news_id'][token_num], rep[0] + \" \" + rep[1],\n",
    "                                                 rep_stock['pk'][rep_num]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "        elif len(rep) == 3:\n",
    "            if rep[0] in token:\n",
    "                try:\n",
    "                    search_found = token[token.index(rep[0]) + 1]\n",
    "                    if rep[1] == search_found:\n",
    "                        two_found = token[token.index(rep[0]) + 2]\n",
    "                        if rep[2] == two_found:\n",
    "                            company_word.loc[i] = [news_raw['news_id'][token_num],\n",
    "                                                     rep[0] + \" \" + rep[1] + \" \" + rep[2], rep_stock['pk'][rep_num]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "company_word = pd.merge(company_word, nasdaq_stock, how='left', left_on='pk', right_on='pk')\n",
    "#company_word = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 뉴스 원문에서 키워드 추출 ( Keybert 사용 )=> 추출 완료 ( keyword.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keybert로 키워드 추출 ( 키워드 1단어들, 2단어들 )\n",
    "summaries = news_raw['summary']\n",
    "# 뉴스 원문 키워드 10개 추출 저장 컬럼\n",
    "news_raw['news_ten_keyword'] = 0\n",
    "\n",
    "for sum_num, summary in enumerate(summaries):\n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(summary,top_n=5)\n",
    "    news_raw['keyword'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 1)) # 뉴스 원문 키워드 한 단어들 다섯개 추출\n",
    "    news_raw['keyword2'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 2)) # 뉴스 원문 키워드 두 단어들 다섯개 추출\n",
    "    news_raw['ten_keyword'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 1),top_n= 10) # 뉴스 원문 키워드 10개 추출\n",
    "#news_raw.to_csv('C:/projectnasdaq/project2/keyword.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 종목 정보 수집 ( yfinance 패키지 사용 ) => 수집완료"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 종목코드 리스트\n",
    "stocks = nasdaq_stock['symbol']\n",
    "# 종목코드에 대한 정보 수집용 데이터프레임 생성\n",
    "stock_info = pd.DataFrame(columns=['symbol', 'info'])\n",
    "i = 0\n",
    "\n",
    "for stock_num, stock in enumerate(stocks):\n",
    "    tickers = yf.Ticker(stock)\n",
    "    ticker = tickers.info\n",
    "    i = i + 1\n",
    "    #print(stock_num,stock, \"===>>\",ticker)\n",
    "    stock_info.loc[i] = [stock, ticker]\n",
    "    time.sleep(random.uniform(3, 4))\n",
    "\n",
    "#stock_info.to_csv('C:/projectnasdaq/project2/stock_info.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 추출된 회사 이름이랑 ( 전처리 한 ) 키워드 연결 ( company_and_keyword.csv 파일에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "company_word = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')\n",
    "keyword = pd.read_csv('C:/projectnasdaq/project2/keyword.csv')\n",
    "\n",
    "# 키워드 전처리\n",
    "keyword['keyword'] = keyword['keyword'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())  # 정규식전처리\n",
    "keyword['keyword'] = keyword['keyword'].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip())  # 공백 여러개 하나로\n",
    "keyword['keyword'] = keyword['keyword'].str.split(\" \")\n",
    "\n",
    "keyword['news_keyword_ten'] = keyword['news_keyword_ten'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())  # 정규식전처리\n",
    "keyword['news_keyword_ten'] = keyword['news_keyword_ten'].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip())  # 공백 여러개 하나로\n",
    "keyword['news_keyword_ten'] = keyword['news_keyword_ten'].str.split(\" \")\n",
    "\n",
    "keyword['keyword2'] = keyword['keyword2'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())\n",
    "keyword['keyword2'] = keyword['keyword2'].str.split(\"  \")\n",
    "\n",
    "\n",
    "# 공백으로 토큰화되거나 비어있는 내용으로 토큰화 되어있으면 지우기\n",
    "keyword['keyword2'] = keyword['keyword2'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "company_word[['keyword', 'keyword2','news_keyword_ten']] = 0\n",
    "\n",
    "keyword_list1 = keyword['keyword']\n",
    "keyword_list2 = keyword['keyword2']\n",
    "\n",
    "keyword_id = keyword['news_id']\n",
    "company_id = company_word['news_id']\n",
    "\n",
    "for i, j in enumerate(company_id):\n",
    "    for k, l in enumerate(keyword_id):\n",
    "        if j == l:\n",
    "            company_word['keyword'][i] = keyword['keyword'][k]\n",
    "            company_word['keyword2'][i] = keyword['keyword2'][k]\n",
    "\n",
    "#company_mapping.to_csv('C:/projectnasdaq/project2/company_and_keyword.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## yahoo_dataset 파일 수정 ( yahoo_dataset_mapping.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# yahoo_dataset 파일 수정 ( -> symbol name 수정 )\n",
    "yahoo_dataset = pd.read_csv('C:/projectnasdaq/project2/yahoo_dataset.csv')\n",
    "# yahoo_dataset에서 필요없는 컬럼들 지우고 csv 파일에 있는 종목코드에 종목명 데이터들 붙임\n",
    "\n",
    "yahoo_dataset.insert(1,'new_symbol','0')\n",
    "yahoo_dataset.insert(2,'name','0')\n",
    "yahoo_dataset.insert(3,'company_word','0')\n",
    "\n",
    "yahoo_dataset_symbol = yahoo_dataset['symbol']\n",
    "rep_stock_symbol = rep_stock['symbol']\n",
    "\n",
    "for i, j in enumerate(yahoo_dataset_symbol):\n",
    "    for k, l in enumerate(rep_stock_symbol):\n",
    "        if j == l:\n",
    "            yahoo_dataset['new_symbol'][i] = rep_stock['symbol'][k]\n",
    "            yahoo_dataset['name'][i] = rep_stock['name'][k]\n",
    "            yahoo_dataset['company_word'][i] = rep_stock['name_a'][k]\n",
    "            break\n",
    "\n",
    "# yahoo_dataset 컬럼 정리\n",
    "yahoo_dataset.drop(columns=[\"quoteType\", \"currency\", 'regularMarketPrice', 'regularMarketChange', 'regularMarketChangePercent',\n",
    "             'regularMarketVolume', 'averageDailyVolume3Month', 'marketCap', 'trailingPE', 'fiftyTwoWeekLow',\n",
    "             'fiftyTwoWeekHigh', 'regularMarketOpen', 'priceHint', 'underlyingSymbol'], inplace=True)\n",
    "#yahoo_dataset.to_csv('C:/projectnasdaq/project2/yahoo_dataset_mapping.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 종목명이 추출된 뉴스 키워드들끼리 모으기 ( 딕셔너리 형태로 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# company단어들 하나씩만 list에 담기 -> 단어 이름이 같은 종목명들의 키워드 모으기 위해서\n",
    "company_and_keyword = pd.read_csv('C:/projectnasdaq/project2/company_and_keyword.csv')\n",
    "company_and_keyword.drop(columns=[\"Unnamed: 0\", 'Unnamed: 0.1'], inplace=True)\n",
    "company_word = company_and_keyword['company_word']\n",
    "\n",
    "company_word_same_list = []\n",
    "for company in company_word:\n",
    "    if company not in company_word_same_list:\n",
    "        company_word_same_list.append(company)\n",
    "\n",
    "company_word_sames = pd.DataFrame(company_word_same_list, columns=['company_word_same'])\n",
    "company_word_same = company_word_sames['company_word_same']\n",
    "\n",
    "# 키워드랑 company_name이랑 데이터프레임에서 맵핑 시키기위한 새로운 dataframe 생성\n",
    "company_name_keyword_organize = pd.DataFrame(columns=['company', 'keyword', 'keyword2','key_list'])\n",
    "\n",
    "# 딕셔너리를 { news_id : keyword } 형태로 만들기 위해서 index를 news_id로 설정\n",
    "company_and_keyword = company_and_keyword.set_index(keys='news_id', drop=False, inplace=False)\n",
    "\n",
    "# company_name에 대한 키워드들 딕셔너리 형태로 모으기\n",
    "for i, j in enumerate(company_word_same):\n",
    "    company_name_keyword_organize.loc[i] = [j, company_and_keyword[company_and_keyword['company_word'] == j]['keyword'].to_dict(), company_and_keyword[company_and_keyword['company_word'] == j]['keyword2'].to_dict(),company_and_keyword[company_and_keyword['company_word'] == j]['keyword'].tolist()] # 리스트 형태로 키워드만 뽑아오기 위해서"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## news_raw_dataset 만들기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# company_name_keyword_organize.csv에 column 삽입\n",
    "company_name_keyword_organize.insert(0, 'symbol','0')\n",
    "company_name_keyword_organize.insert(1, 'name','0')\n",
    "company_name_keyword_organize.insert(2, 'shortName','0')\n",
    "company_name_keyword_organize.insert(3, 'longName','0')\n",
    "company_name_keyword_organize.insert(5, 'company_info','0')\n",
    "\n",
    "yahoo_dataset_mapping = pd.read_csv('C:/projectnasdaq/project2/yahoo_dataset_mapping.csv')\n",
    "company_word_csv = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')\n",
    "\n",
    "# company_name_keyword_organize.csv에 symbol, name 데이터 삽입\n",
    "company_word = company_word_csv['company_word']\n",
    "company = company_name_keyword_organize['company']\n",
    "\n",
    "for i,j in enumerate(company_word):\n",
    "    for k, l in enumerate(company):\n",
    "        if j==l:\n",
    "            company_name_keyword_organize['symbol'][k] = company_word_csv['symbol'][i]\n",
    "            company_name_keyword_organize['name'][k] = company_word_csv['name'][i]\n",
    "            break\n",
    "\n",
    "# company__name.csv에 yahoo finance 정보 수집 내용 삽입\n",
    "yahoo_dataset_mapping_symbol = yahoo_dataset_mapping['new_symbol']\n",
    "company_name_keyword_organize_symbol = company_name_keyword_organize['symbol']\n",
    "\n",
    "for i,j in enumerate(yahoo_dataset_mapping_symbol):\n",
    "    for k,l in enumerate(company_name_keyword_organize_symbol):\n",
    "        if j==l:\n",
    "            company_name_keyword_organize['shortName'][k] = yahoo_dataset_mapping['shortName'][i]\n",
    "            company_name_keyword_organize['longName'][k] = yahoo_dataset_mapping['longName'][i]\n",
    "            company_name_keyword_organize['company_info'][k] = yahoo_dataset_mapping['company_info'][i]\n",
    "            break\n",
    "\n",
    "# 대표 키워드 추출하기\n",
    "# 키워드 빈도수 순으로 정리해서 5개까지만 뽑아오기\n",
    "company_name_keyword_organize['frequency'] = 0\n",
    "company_name_keyword_organize\n",
    "\n",
    "key_list_ = company_name_keyword_organize['key_list']\n",
    "for i, j in enumerate(key_list_):\n",
    "        company_name_keyword_organize['key_list'][i] = ''.join(j)\n",
    "\n",
    "company_name_keyword_organize['key_list'].replace(['\\]','\\[','\\''],'',regex=True, inplace=True)\n",
    "company_name_keyword_organize['key_list'].replace(',',' ',regex=True, inplace=True)\n",
    "company_name_keyword_organize['key_list'] = company_name_keyword_organize['key_list'].str.split(\" \")\n",
    "company_name_keyword_organize['key_list'] = company_name_keyword_organize['key_list']\\\n",
    "    .apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "\n",
    "frequency_word = company_name_keyword_organize['key_list']\n",
    "for i, j in enumerate(frequency_word):\n",
    "    # 대표 키워드 빈도순으로 5개 추출\n",
    "    company_name_keyword_organize['frequency'][i] = Counter(j).most_common(5)\n",
    "# 다섯개 뽑아온 키워드 전처리\n",
    "company_name_keyword_organize['frequency'] = company_name_keyword_organize['frequency']\\\n",
    "    .apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())\n",
    "company_name_keyword_organize['frequency'] = company_name_keyword_organize['frequency'].str.split(\" \")\n",
    "company_name_keyword_organize['frequency'] = company_name_keyword_organize['frequency']\\\n",
    "    .apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "# 완성된 news_raw dataset\n",
    "#company__name.to_csv('C:/projectnasdaq/project2/news_raw_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 맵핑 (1) 뉴스 원문에 종목명의 대표 키워드가 포함될 때"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 맵핑 수 : 543\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 원문에 대표 키워드가 포함될 경우 news_id와 symbol 맵핑\n",
    "frequency = company_name_keyword_organize['frequency'] # 키워드 빈도수로 정렬 후 5개만 담아온 리스트\n",
    "news_stock_mapping = pd.DataFrame(columns=['news_id', 'symbol','name','summary','frequency'])\n",
    "\n",
    "a = 0\n",
    "for i, j in enumerate(tokenize_list):\n",
    "    for k,l in enumerate(frequency):\n",
    "        a = a + 1\n",
    "        #print(news_raw['news_id'][i])\n",
    "        together = set(j)&set(l)\n",
    "        # 뉴스 원문에 대표 키워드가 4개 이상 교집합으로 있을 경우\n",
    "        if len(together)==5:\n",
    "            news_stock_mapping.loc[a] = [news_raw['news_id'][i], company_name_keyword_organize['symbol'][k], company_name_keyword_organize['name'][k],news_raw['summary'][i], company_name_keyword_organize['frequency'][k]]\n",
    "\n",
    "print('총 맵핑 수 :',len(news_stock_mapping))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 맵핑(2) 뉴스 원문 키워드(10개)랑 종목명의 대표 키워드가 일치할 때"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 맵핑 수 : 1099\n"
     ]
    }
   ],
   "source": [
    "news_stock_mapping_2 = pd.DataFrame(columns=['news_id', 'symbol','name','summary','frequency','news_keyword_ten'])\n",
    "news_raw_keyword_ten = company_name_keyword_organize['frequency']\n",
    "# frequency => 종목명의 대표키워드\n",
    "a=0\n",
    "for i,j in enumerate(news_raw_keyword_ten):\n",
    "    for k,l in enumerate(frequency):\n",
    "        a=a+1\n",
    "        together = set(j)&set(l)\n",
    "        if len(together)>=4:\n",
    "            news_stock_mapping_2.loc[a] = [keyword['news_id'][i], company_name_keyword_organize['symbol'][k], company_name_keyword_organize['name'][k],keyword['summary'][i], company_name_keyword_organize['frequency'][k],keyword['news_keyword_ten'][i]]\n",
    "\n",
    "print('총 맵핑 수 :',len(news_stock_mapping_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}