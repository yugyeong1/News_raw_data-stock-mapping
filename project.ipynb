{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from keybert import KeyBERT\n",
    "import yfinance as yf\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "news_raw = pd.read_csv(\"C:/projectnasdaq/news_raw.csv\", encoding='latin1')\n",
    "nasdaq_stock = pd.read_csv(\"C:/projectnasdaq/nasdaq_stocks.csv\", encoding='latin1')\n",
    "rep_stock = pd.read_csv(\"C:/projectnasdaq/nasdaq_stocks_refine_total.csv\", encoding='latin1')\n",
    "\n",
    "news_raw = news_raw.head(1000)\n",
    "news_raw = news_raw[['news_id','title','summary']]\n",
    "nasdaq_stock = nasdaq_stock[['pk','symbol','name']]\n",
    "rep_stock = rep_stock[['pk','symbol','name','name_a']]\n",
    "\n",
    "# new_raw 데이터 전처리\n",
    "news_raw['summary'] = news_raw['summary'].str.lower()\n",
    "news_raw['summary'] = news_raw['summary'].apply(lambda x: re.sub('[^a-zA-Z\\d&]', ' ', str(x)).strip())\n",
    "self_stop_words = {'bloomberg'}\n",
    "news_raw['summary'].replace(self_stop_words, '', regex=True, inplace=True)\n",
    "\n",
    "# news_raw 데이터 토큰화\n",
    "news_raw['tokenize'] = 0\n",
    "news_raw['tokenize'] = news_raw['summary'].str.split(\" \")\n",
    "news_raw['tokenize'] = news_raw['tokenize'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "news_raw['company_name'] = 0\n",
    "news_raw['keyword'] = 0 # keybert로 뽑아낸 키워드 컬럼\n",
    "news_raw['keyword2'] = 0\n",
    "\n",
    "# list에 담아주기\n",
    "tokenize_list = news_raw['tokenize']\n",
    "rep_list = rep_stock['name_a'].str.split(\",\")\n",
    "\n",
    "# 맵핑한 데이터 저장하기 위한 csv파일 생성\n",
    "project_result = pd.DataFrame(columns=['news_id', 'company_word','pk'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    news_id                                              title  \\\n0    345585  Nestle Outshines Rivals With Revenue Growth Le...   \n1    345586  Total Makes Surprise Profit as Trading Gains O...   \n2    345590  Airbus Follows Boeing in Paring Output to Weat...   \n3    345591  Virus Uptick Imperils South Europe's Nascent T...   \n4    345595  PG&E Fire Insurance Costs Skyrocket After Bank...   \n..      ...                                                ...   \n995  443773  Localiza to Form $9 Billion Car-Rental Giant W...   \n996  443778  Mendoza Province Is First to Restructure After...   \n997  443779  Manufacturing Keeps German Economy on a Recove...   \n998  443780  ECB Must Limit Emergency Powers to Temporary C...   \n999  443781  Citi Pledges to Become Antiracist, Review Inte...   \n\n                                               summary  \\\n0         nestle sa sailed past ailing consumer goo...   \n1         total se made a surprise profit after  ve...   \n2         airbus se cut back wide body jet producti...   \n3         nadine scheiner s efforts to travel from ...   \n4         pg&e corp  is finding it very costly to b...   \n..                                                 ...   \n995       localiza rent a car sa and unidas  two of...   \n996       argentina s mendoza province has reached ...   \n997       german factories kept europe s biggest ec...   \n998       the european central bank risks legal tro...   \n999       citigroup inc  will spend  1 billion over...   \n\n                                              tokenize  company_name  keyword  \\\n0    [nestle, sa, sailed, past, ailing, consumer, g...             0        0   \n1    [total, se, made, a, surprise, profit, after, ...             0        0   \n2    [airbus, se, cut, back, wide, body, jet, produ...             0        0   \n3    [nadine, scheiner, s, efforts, to, travel, fro...             0        0   \n4    [pg&e, corp, is, finding, it, very, costly, to...             0        0   \n..                                                 ...           ...      ...   \n995  [localiza, rent, a, car, sa, and, unidas, two,...             0        0   \n996  [argentina, s, mendoza, province, has, reached...             0        0   \n997  [german, factories, kept, europe, s, biggest, ...             0        0   \n998  [the, european, central, bank, risks, legal, t...             0        0   \n999  [citigroup, inc, will, spend, 1, billion, over...             0        0   \n\n     keyword2  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  \n..        ...  \n995         0  \n996         0  \n997         0  \n998         0  \n999         0  \n\n[1000 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>news_id</th>\n      <th>title</th>\n      <th>summary</th>\n      <th>tokenize</th>\n      <th>company_name</th>\n      <th>keyword</th>\n      <th>keyword2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>345585</td>\n      <td>Nestle Outshines Rivals With Revenue Growth Le...</td>\n      <td>nestle sa sailed past ailing consumer goo...</td>\n      <td>[nestle, sa, sailed, past, ailing, consumer, g...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>345586</td>\n      <td>Total Makes Surprise Profit as Trading Gains O...</td>\n      <td>total se made a surprise profit after  ve...</td>\n      <td>[total, se, made, a, surprise, profit, after, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>345590</td>\n      <td>Airbus Follows Boeing in Paring Output to Weat...</td>\n      <td>airbus se cut back wide body jet producti...</td>\n      <td>[airbus, se, cut, back, wide, body, jet, produ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>345591</td>\n      <td>Virus Uptick Imperils South Europe's Nascent T...</td>\n      <td>nadine scheiner s efforts to travel from ...</td>\n      <td>[nadine, scheiner, s, efforts, to, travel, fro...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>345595</td>\n      <td>PG&amp;E Fire Insurance Costs Skyrocket After Bank...</td>\n      <td>pg&amp;e corp  is finding it very costly to b...</td>\n      <td>[pg&amp;e, corp, is, finding, it, very, costly, to...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>443773</td>\n      <td>Localiza to Form $9 Billion Car-Rental Giant W...</td>\n      <td>localiza rent a car sa and unidas  two of...</td>\n      <td>[localiza, rent, a, car, sa, and, unidas, two,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>443778</td>\n      <td>Mendoza Province Is First to Restructure After...</td>\n      <td>argentina s mendoza province has reached ...</td>\n      <td>[argentina, s, mendoza, province, has, reached...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>443779</td>\n      <td>Manufacturing Keeps German Economy on a Recove...</td>\n      <td>german factories kept europe s biggest ec...</td>\n      <td>[german, factories, kept, europe, s, biggest, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>443780</td>\n      <td>ECB Must Limit Emergency Powers to Temporary C...</td>\n      <td>the european central bank risks legal tro...</td>\n      <td>[the, european, central, bank, risks, legal, t...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>443781</td>\n      <td>Citi Pledges to Become Antiracist, Review Inte...</td>\n      <td>citigroup inc  will spend  1 billion over...</td>\n      <td>[citigroup, inc, will, spend, 1, billion, over...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 회사 이름 추출 => 추출 완료 ( company_word.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 대표단어 csv파일에서 대표단어가 포함되면 맵핑\n",
    "i = 0\n",
    "\n",
    "for token_num, token in enumerate(tokenize_list):  # news_raw data 토큰화\n",
    "    for rep_num, rep in enumerate(rep_list):  # 대표단어 csv파일에서 대표단어에 해당\n",
    "        i = i + 1\n",
    "        if len(rep) == 1:\n",
    "            if rep[0] in token:\n",
    "                project_result.loc[i] = [news_raw['news_id'][token_num], rep[0], rep_stock['pk'][rep_num]]\n",
    "\n",
    "        elif len(rep) == 2:  # 대표단어가 2개로 된 단어일 때\n",
    "            if rep[0] in token:  # 대표단어의 첫번째 단어가 org단어에 있으면\n",
    "                found = token.index(rep[0])  # 대표단어의 첫번째 단어와 일치하는 org단어의 인덱스 위치 번호\n",
    "                try:\n",
    "                    search = found + 1  # stocklist의 첫번째 단어가 org에 포함됐을때 그 다음 단어\n",
    "                    search_found = token[search]  # org의 (+1을 한) 다음 단어에 해당\n",
    "                    if rep[1] == search_found:\n",
    "                        project_result.loc[i] = [news_raw['news_id'][token_num], rep[0] + \" \" + rep[1],\n",
    "                                                 rep_stock['pk'][rep_num]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "        elif len(rep) == 3:\n",
    "            if rep[0] in token:\n",
    "                try:\n",
    "                    search_found = token[token.index(rep[0]) + 1]\n",
    "                    if rep[1] == search_found:\n",
    "                        two_found = token[token.index(rep[0]) + 2]\n",
    "                        if rep[2] == two_found:\n",
    "                            project_result.loc[i] = [news_raw['news_id'][token_num],\n",
    "                                                     rep[0] + \" \" + rep[1] + \" \" + rep[2], rep_stock['pk'][rep_num]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "project_result = pd.merge(project_result, nasdaq_stock, how='left', left_on='pk', right_on='pk')\n",
    "\n",
    "company_word = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 뉴스 원문에서 키워드 추출 ( Keybert 사용 )=> 추출 완료 ( keyword.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keybert로 키워드 추출 ( 키워드 1단어들, 2단어들 )\n",
    "summaries = news_raw['summary']\n",
    "# 뉴스 원문 키워드 10개 추출 ( 대표키워드랑 비교용도 )\n",
    "news_raw['ten_keyword'] = 0\n",
    "\n",
    "for sum_num, summary in enumerate(summaries):\n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(summary,top_n=5)\n",
    "    news_raw['keyword'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 1))\n",
    "    news_raw['keyword2'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 2))\n",
    "    news_raw['ten_keyword'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 1),top_n= 10)\n",
    "#news_raw.to_csv('C:/projectnasdaq/project2/keyword.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 종목 정보 수집 ( yfinance 패키지 사용 ) => 수집완료"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 종목코드 리스트\n",
    "stocks = nasdaq_stock['symbol']\n",
    "# 종목코드에 대한 정보 수집용 데이터프레임 생성\n",
    "stock_info = pd.DataFrame(columns=['symbol', 'info'])\n",
    "i = 0\n",
    "\n",
    "for stock_num, stock in enumerate(stocks):\n",
    "    tickers = yf.Ticker(stock)\n",
    "    ticker = tickers.info\n",
    "    i = i + 1\n",
    "    #print(stock_num,stock, \"===>>\",ticker)\n",
    "    stock_info.loc[i] = [stock, ticker]\n",
    "    time.sleep(random.uniform(3, 4))\n",
    "\n",
    "#stock_info.to_csv('C:/projectnasdaq/project2/stock_info.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 추출된 회사 이름이랑 ( 전처리 한 ) 키워드 연결 ( company_and_keyword.csv 파일에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "company_mapping = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')\n",
    "keyword_mapping = pd.read_csv('C:/projectnasdaq/project2/keyword.csv')\n",
    "\n",
    "keyword_mapping['keyword'] = keyword_mapping['keyword'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())  # 정규식전처리\n",
    "keyword_mapping['keyword'] = keyword_mapping['keyword'].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip())  # 공백 여러개 하나로\n",
    "keyword_mapping['keyword'] = keyword_mapping['keyword'].str.split(\" \")\n",
    "#keyword_mapping['keyword'].replace(' ',',', regex=True, inplace=True)\n",
    "\n",
    "keyword_mapping['keyword2'] = keyword_mapping['keyword2'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())\n",
    "keyword_mapping['keyword2'] = keyword_mapping['keyword2'].str.split(\"  \")\n",
    "# 공백으로 토큰화되거나 비어있는 내용으로 토큰화 되어있으면 지우기\n",
    "keyword_mapping['keyword2'] = keyword_mapping['keyword2'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "company_mapping[['keyword', 'keyword2']] = 0\n",
    "\n",
    "keyword_list1 = keyword_mapping['keyword']\n",
    "keyword_list2 = keyword_mapping['keyword2']\n",
    "\n",
    "keyword_id = keyword_mapping['news_id']\n",
    "company_id = company_mapping['news_id']\n",
    "\n",
    "for i, j in enumerate(company_id):\n",
    "    for k, l in enumerate(keyword_id):\n",
    "        if j == l:\n",
    "            company_mapping['keyword'][i] = keyword_mapping['keyword'][k]\n",
    "            company_mapping['keyword2'][i] = keyword_mapping['keyword2'][k]\n",
    "\n",
    "#company_mapping.to_csv('C:/projectnasdaq/project2/company_and_keyword.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## yahoo_dataset 파일 수정 ( yahoo_dataset_mapping.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# yahoo_dataset 파일 수정 ( -> symbol name 수정 )\n",
    "yahoo_dataset = pd.read_csv('C:/projectnasdaq/project2/yahoo_dataset.csv')\n",
    "yahoo_dataset.insert(1,'new_symbol','0')\n",
    "yahoo_dataset.insert(2,'name','0')\n",
    "yahoo_dataset.insert(3,'company_word','0')\n",
    "\n",
    "yahoo_dataset_symbol = yahoo_dataset['symbol']\n",
    "rep_stock_symbol = rep_stock['symbol']\n",
    "\n",
    "for i, j in enumerate(yahoo_dataset_symbol):\n",
    "    for k, l in enumerate(rep_stock_symbol):\n",
    "        if j == l:\n",
    "            yahoo_dataset['new_symbol'][i] = rep_stock['symbol'][k]\n",
    "            yahoo_dataset['name'][i] = rep_stock['name'][k]\n",
    "            yahoo_dataset['company_word'][i] = rep_stock['name_a'][k]\n",
    "            break\n",
    "\n",
    "# yahoo_dataset 컬럼 정리\n",
    "yahoo_dataset.drop(columns=[\"quoteType\", \"currency\", 'regularMarketPrice', 'regularMarketChange', 'regularMarketChangePercent',\n",
    "             'regularMarketVolume', 'averageDailyVolume3Month', 'marketCap', 'trailingPE', 'fiftyTwoWeekLow',\n",
    "             'fiftyTwoWeekHigh', 'regularMarketOpen', 'priceHint', 'underlyingSymbol'], inplace=True)\n",
    "yahoo_dataset.to_csv('C:/projectnasdaq/project2/yahoo_dataset_mapping.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 종목명이 추출된 뉴스 키워드들끼리 모으기 ( 딕셔너리 형태로 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# company단어들 하나씩만 list에 담기 -> 단어 이름이 같은 종목명들의 키워드 모으기 위해서\n",
    "company_and_keyword = pd.read_csv('C:/projectnasdaq/project2/company_and_keyword.csv')\n",
    "company_and_keyword.drop(columns=[\"Unnamed: 0\", 'Unnamed: 0.1'], inplace=True)\n",
    "company_word = company_and_keyword['company_word']\n",
    "\n",
    "company_word_same_list = []\n",
    "for company in company_word:\n",
    "    if company not in company_word_same_list:\n",
    "        company_word_same_list.append(company)\n",
    "\n",
    "company_word_sames = pd.DataFrame(company_word_same_list, columns=['company_word_same'])\n",
    "company_word_same = company_word_sames['company_word_same']\n",
    "\n",
    "# 키워드랑 company_name이랑 데이터프레임에서 맵핑 시키기위한 새로운 dataframe 생성\n",
    "company__name = pd.DataFrame(columns=['company', 'keyword', 'keyword2','key_list'])\n",
    "\n",
    "# 딕셔너리를 { news_id : keyword } 형태로 만들기 위해서 index를 news_id로 설정\n",
    "company_and_keyword = company_and_keyword.set_index(keys='news_id', drop=False, inplace=False)\n",
    "\n",
    "# company__name에 대한 키워드들 딕셔너리 형태로 모으기\n",
    "for i, j in enumerate(company_word_same):\n",
    "    company__name.loc[i] = [j, company_and_keyword[company_and_keyword['company_word'] == j]['keyword'].to_dict(), company_and_keyword[company_and_keyword['company_word'] == j]['keyword2'].to_dict(),company_and_keyword[company_and_keyword['company_word'] == j]['keyword'].tolist()] # 리스트 형태로 키워드만 뽑아오기 위해서"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## news_raw_dataset 만들기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# company__name.csv에 column 삽입\n",
    "company__name.insert(0, 'symbol','0')\n",
    "company__name.insert(1, 'name','0')\n",
    "company__name.insert(2, 'shortName','0')\n",
    "company__name.insert(3, 'longName','0')\n",
    "company__name.insert(5, 'company_info','0')\n",
    "\n",
    "yahoo_dataset_mapping = pd.read_csv('C:/projectnasdaq/project2/yahoo_dataset_mapping.csv')\n",
    "company_word = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')\n",
    "\n",
    "# company__name.csv에 symbol, name 데이터 삽입\n",
    "company_word_ = company_word['company_word']\n",
    "company__ = company__name['company']\n",
    "\n",
    "for i,j in enumerate(company_word_):\n",
    "    for k, l in enumerate(company__):\n",
    "        if j==l:\n",
    "            company__name['symbol'][k] = company_word['symbol'][i]\n",
    "            company__name['name'][k] = company_word['name'][i]\n",
    "            break\n",
    "\n",
    "# company__name.csv에 yahoo finance 정보 수집 내용 삽입\n",
    "yahoo_dataset_mapping_symbol = yahoo_dataset_mapping['new_symbol']\n",
    "company__name_symbol = company__name['symbol']\n",
    "\n",
    "for i,j in enumerate(yahoo_dataset_mapping_symbol):\n",
    "    for k,l in enumerate(company__name_symbol):\n",
    "        if j==l:\n",
    "            company__name['shortName'][k] = yahoo_dataset_mapping['shortName'][i]\n",
    "            company__name['longName'][k] = yahoo_dataset_mapping['longName'][i]\n",
    "            company__name['company_info'][k] = yahoo_dataset_mapping['company_info'][i]\n",
    "            break\n",
    "\n",
    "# 완성된 news_raw dataset\n",
    "#company__name.to_csv('C:/projectnasdaq/project2/news_raw_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 대표 키워드 추출"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 키워드 빈도수 순으로 정리해서 5개까지만 뽑아오기\n",
    "company__name['frequency_word'] = 0\n",
    "company__name['frequency'] = 0\n",
    "\n",
    "key_list_ = company__name['key_list']\n",
    "for i, j in enumerate(key_list_):\n",
    "        company__name['frequency_word'][i] = ''.join(j)\n",
    "\n",
    "company__name['frequency_word'].replace(['\\]','\\[','\\''],'',regex=True, inplace=True)\n",
    "company__name['frequency_word'].replace(',',' ',regex=True, inplace=True)\n",
    "company__name['frequency_word'] = company__name['frequency_word'].str.split(\" \")\n",
    "company__name['frequency_word'] = company__name['frequency_word'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "frequency_words = company__name['frequency_word']\n",
    "for i, j in enumerate(frequency_words):\n",
    "    # 대표 키워드 빈도순으로 5개 추출\n",
    "    company__name['frequency'][i] = Counter(j).most_common(5)\n",
    "\n",
    "# 다섯개 뽑아온 키워드 전처리\n",
    "company__name['frequency'] = company__name['frequency'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())\n",
    "company__name['frequency'] = company__name['frequency'].str.split(\" \")\n",
    "company__name['frequency'] = company__name['frequency'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "# 뉴스 원문에 대표 키워드가 포함될 경우 news_id와 symbol 맵핑\n",
    "frequency = company__name['frequency'] # 키워드 빈도수로 정렬 후 5개만 담아온 리스트\n",
    "news_stock_mapping = pd.DataFrame(columns=['news_id', 'symbol','name','summary','frequency'])\n",
    "\n",
    "a = 0\n",
    "for i, j in enumerate(tokenize_list):\n",
    "    for k,l in enumerate(frequency):\n",
    "        a = a + 1\n",
    "        #print(news_raw['news_id'][i])\n",
    "        together = set(j)&set(l)\n",
    "        # 뉴스 원문에 대표 키워드가 4개 이상 교집합으로 있을 경우\n",
    "        if len(together)==5:\n",
    "            news_stock_mapping.loc[a] = [news_raw['news_id'][i], company__name['symbol'][k], company__name['name'][k],                                                 news_raw['summary'][i], company__name['frequency'][k]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 맵핑 수 : 544\n"
     ]
    }
   ],
   "source": [
    "print('총 맵핑 수 :',len(news_stock_mapping))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}