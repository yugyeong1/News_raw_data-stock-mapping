{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from keybert import KeyBERT\n",
    "import yfinance as yf\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "news_raw = pd.read_csv(\"C:/projectnasdaq/news_raw.csv\", encoding='latin1')\n",
    "nasdaq_stock = pd.read_csv(\"C:/projectnasdaq/nasdaq_stocks.csv\", encoding='latin1')\n",
    "rep_stock = pd.read_csv(\"C:/projectnasdaq/nasdaq_stocks_refine_total.csv\", encoding='latin1')\n",
    "\n",
    "news_raw = news_raw.head(1000)\n",
    "news_raw = news_raw[['news_id','title','summary']]\n",
    "nasdaq_stock = nasdaq_stock[['pk','symbol','name']]\n",
    "rep_stock = rep_stock[['pk','symbol','name','name_a']]\n",
    "\n",
    "# new_raw 데이터 전처리\n",
    "news_raw['summary'] = news_raw['summary'].str.lower()\n",
    "news_raw['summary'] = news_raw['summary'].apply(lambda x: re.sub('[^a-zA-Z\\d&]', ' ', str(x)).strip())\n",
    "self_stop_words = {'bloomberg'}\n",
    "news_raw['summary'].replace(self_stop_words, '', regex=True, inplace=True)\n",
    "\n",
    "# news_raw 데이터 토큰화\n",
    "news_raw['tokenize'] = 0\n",
    "news_raw['tokenize'] = news_raw['summary'].str.split(\" \")\n",
    "news_raw['tokenize'] = news_raw['tokenize'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "news_raw['company_name'] = 0\n",
    "news_raw['keyword'] = 0 # keybert로 뽑아낸 키워드 컬럼\n",
    "news_raw['keyword2'] = 0\n",
    "\n",
    "# list에 담아주기\n",
    "tokenize_list = news_raw['tokenize']\n",
    "rep_list = rep_stock['name_a'].str.split(\",\")\n",
    "\n",
    "# 맵핑한 데이터 저장하기 위한 csv파일 생성\n",
    "project_result = pd.DataFrame(columns=['news_id', 'company_word','pk'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    news_id                                              title  \\\n0    345585  Nestle Outshines Rivals With Revenue Growth Le...   \n1    345586  Total Makes Surprise Profit as Trading Gains O...   \n2    345590  Airbus Follows Boeing in Paring Output to Weat...   \n3    345591  Virus Uptick Imperils South Europe's Nascent T...   \n4    345595  PG&E Fire Insurance Costs Skyrocket After Bank...   \n..      ...                                                ...   \n995  443773  Localiza to Form $9 Billion Car-Rental Giant W...   \n996  443778  Mendoza Province Is First to Restructure After...   \n997  443779  Manufacturing Keeps German Economy on a Recove...   \n998  443780  ECB Must Limit Emergency Powers to Temporary C...   \n999  443781  Citi Pledges to Become Antiracist, Review Inte...   \n\n                                               summary  \\\n0         nestle sa sailed past ailing consumer goo...   \n1         total se made a surprise profit after  ve...   \n2         airbus se cut back wide body jet producti...   \n3         nadine scheiner s efforts to travel from ...   \n4         pg&e corp  is finding it very costly to b...   \n..                                                 ...   \n995       localiza rent a car sa and unidas  two of...   \n996       argentina s mendoza province has reached ...   \n997       german factories kept europe s biggest ec...   \n998       the european central bank risks legal tro...   \n999       citigroup inc  will spend  1 billion over...   \n\n                                              tokenize  company_name  keyword  \\\n0    [nestle, sa, sailed, past, ailing, consumer, g...             0        0   \n1    [total, se, made, a, surprise, profit, after, ...             0        0   \n2    [airbus, se, cut, back, wide, body, jet, produ...             0        0   \n3    [nadine, scheiner, s, efforts, to, travel, fro...             0        0   \n4    [pg&e, corp, is, finding, it, very, costly, to...             0        0   \n..                                                 ...           ...      ...   \n995  [localiza, rent, a, car, sa, and, unidas, two,...             0        0   \n996  [argentina, s, mendoza, province, has, reached...             0        0   \n997  [german, factories, kept, europe, s, biggest, ...             0        0   \n998  [the, european, central, bank, risks, legal, t...             0        0   \n999  [citigroup, inc, will, spend, 1, billion, over...             0        0   \n\n     keyword2  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  \n..        ...  \n995         0  \n996         0  \n997         0  \n998         0  \n999         0  \n\n[1000 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>news_id</th>\n      <th>title</th>\n      <th>summary</th>\n      <th>tokenize</th>\n      <th>company_name</th>\n      <th>keyword</th>\n      <th>keyword2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>345585</td>\n      <td>Nestle Outshines Rivals With Revenue Growth Le...</td>\n      <td>nestle sa sailed past ailing consumer goo...</td>\n      <td>[nestle, sa, sailed, past, ailing, consumer, g...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>345586</td>\n      <td>Total Makes Surprise Profit as Trading Gains O...</td>\n      <td>total se made a surprise profit after  ve...</td>\n      <td>[total, se, made, a, surprise, profit, after, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>345590</td>\n      <td>Airbus Follows Boeing in Paring Output to Weat...</td>\n      <td>airbus se cut back wide body jet producti...</td>\n      <td>[airbus, se, cut, back, wide, body, jet, produ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>345591</td>\n      <td>Virus Uptick Imperils South Europe's Nascent T...</td>\n      <td>nadine scheiner s efforts to travel from ...</td>\n      <td>[nadine, scheiner, s, efforts, to, travel, fro...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>345595</td>\n      <td>PG&amp;E Fire Insurance Costs Skyrocket After Bank...</td>\n      <td>pg&amp;e corp  is finding it very costly to b...</td>\n      <td>[pg&amp;e, corp, is, finding, it, very, costly, to...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>443773</td>\n      <td>Localiza to Form $9 Billion Car-Rental Giant W...</td>\n      <td>localiza rent a car sa and unidas  two of...</td>\n      <td>[localiza, rent, a, car, sa, and, unidas, two,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>443778</td>\n      <td>Mendoza Province Is First to Restructure After...</td>\n      <td>argentina s mendoza province has reached ...</td>\n      <td>[argentina, s, mendoza, province, has, reached...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>443779</td>\n      <td>Manufacturing Keeps German Economy on a Recove...</td>\n      <td>german factories kept europe s biggest ec...</td>\n      <td>[german, factories, kept, europe, s, biggest, ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>443780</td>\n      <td>ECB Must Limit Emergency Powers to Temporary C...</td>\n      <td>the european central bank risks legal tro...</td>\n      <td>[the, european, central, bank, risks, legal, t...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>443781</td>\n      <td>Citi Pledges to Become Antiracist, Review Inte...</td>\n      <td>citigroup inc  will spend  1 billion over...</td>\n      <td>[citigroup, inc, will, spend, 1, billion, over...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 회사 이름 추출 => 추출 완료 ( company_word.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 대표단어 csv파일에서 대표단어가 포함되면 맵핑\n",
    "i = 0\n",
    "\n",
    "for token_num, token in enumerate(tokenize_list):  # news_raw data 토큰화\n",
    "    for rep_num, rep in enumerate(rep_list):  # 대표단어 csv파일에서 대표단어에 해당\n",
    "        i = i + 1\n",
    "        if len(rep) == 1:\n",
    "            if rep[0] in token:\n",
    "                project_result.loc[i] = [news_raw['news_id'][token_num], rep[0], rep_stock['pk'][rep_num]]\n",
    "\n",
    "        elif len(rep) == 2:  # 대표단어가 2개로 된 단어일 때\n",
    "            if rep[0] in token:  # 대표단어의 첫번째 단어가 org단어에 있으면\n",
    "                found = token.index(rep[0])  # 대표단어의 첫번째 단어와 일치하는 org단어의 인덱스 위치 번호\n",
    "                try:\n",
    "                    search = found + 1  # stocklist의 첫번째 단어가 org에 포함됐을때 그 다음 단어\n",
    "                    search_found = token[search]  # org의 (+1을 한) 다음 단어에 해당\n",
    "                    if rep[1] == search_found:\n",
    "                        project_result.loc[i] = [news_raw['news_id'][token_num], rep[0] + \" \" + rep[1],\n",
    "                                                 rep_stock['pk'][rep_num]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "        elif len(rep) == 3:\n",
    "            if rep[0] in token:\n",
    "                try:\n",
    "                    search_found = token[token.index(rep[0]) + 1]\n",
    "                    if rep[1] == search_found:\n",
    "                        two_found = token[token.index(rep[0]) + 2]\n",
    "                        if rep[2] == two_found:\n",
    "                            project_result.loc[i] = [news_raw['news_id'][token_num],\n",
    "                                                     rep[0] + \" \" + rep[1] + \" \" + rep[2], rep_stock['pk'][rep_num]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "project_result = pd.merge(project_result, nasdaq_stock, how='left', left_on='pk', right_on='pk')\n",
    "\n",
    "company_word = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 뉴스 원문에서 키워드 추출 ( Keybert 사용 )=> 추출 완료 ( keyword.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keybert로 키워드 추출 ( 키워드 1단어들, 2단어들 )\n",
    "summaries = news_raw['summary']\n",
    "# 뉴스 원문 키워드 10개 추출 ( 대표키워드랑 비교용도 )\n",
    "news_raw['ten_keyword'] = 0\n",
    "\n",
    "for sum_num, summary in enumerate(summaries):\n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(summary,top_n=5)\n",
    "    news_raw['keyword'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 1))\n",
    "    news_raw['keyword2'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 2))\n",
    "    news_raw['ten_keyword'][sum_num] = kw_model.extract_keywords(summary, keyphrase_ngram_range=(1, 1),top_n= 10)\n",
    "#news_raw.to_csv('C:/projectnasdaq/project2/keyword.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 종목 정보 수집 ( yfinance 패키지 사용 ) => 수집완료"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 종목코드 리스트\n",
    "stocks = nasdaq_stock['symbol']\n",
    "# 종목코드에 대한 정보 수집용 데이터프레임 생성\n",
    "stock_info = pd.DataFrame(columns=['symbol', 'info'])\n",
    "i = 0\n",
    "\n",
    "for stock_num, stock in enumerate(stocks):\n",
    "    tickers = yf.Ticker(stock)\n",
    "    ticker = tickers.info\n",
    "    i = i + 1\n",
    "    #print(stock_num,stock, \"===>>\",ticker)\n",
    "    stock_info.loc[i] = [stock, ticker]\n",
    "    time.sleep(random.uniform(3, 4))\n",
    "\n",
    "#stock_info.to_csv('C:/projectnasdaq/project2/stock_info.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 추출된 회사 이름이랑 ( 전처리 한 ) 키워드 연결 ( company_and_keyword.csv 파일에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "company_mapping = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')\n",
    "keyword_mapping = pd.read_csv('C:/projectnasdaq/project2/keyword.csv')\n",
    "\n",
    "# 키워드 전처리\n",
    "keyword_mapping['keyword'] = keyword_mapping['keyword'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())  # 정규식전처리\n",
    "keyword_mapping['keyword'] = keyword_mapping['keyword'].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip())  # 공백 여러개 하나로\n",
    "keyword_mapping['keyword'] = keyword_mapping['keyword'].str.split(\" \")\n",
    "\n",
    "keyword_mapping['keyword_ten'] = keyword_mapping['keyword_ten'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())  # 정규식전처리\n",
    "keyword_mapping['keyword_ten'] = keyword_mapping['keyword_ten'].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip())  # 공백 여러개 하나로\n",
    "keyword_mapping['keyword_ten'] = keyword_mapping['keyword_ten'].str.split(\" \")\n",
    "\n",
    "keyword_mapping['keyword2'] = keyword_mapping['keyword2'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())\n",
    "keyword_mapping['keyword2'] = keyword_mapping['keyword2'].str.split(\"  \")\n",
    "\n",
    "\n",
    "# 공백으로 토큰화되거나 비어있는 내용으로 토큰화 되어있으면 지우기\n",
    "keyword_mapping['keyword2'] = keyword_mapping['keyword2'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "company_mapping[['keyword', 'keyword2','keyword_ten']] = 0\n",
    "\n",
    "keyword_list1 = keyword_mapping['keyword']\n",
    "keyword_list2 = keyword_mapping['keyword2']\n",
    "\n",
    "keyword_id = keyword_mapping['news_id']\n",
    "company_id = company_mapping['news_id']\n",
    "\n",
    "for i, j in enumerate(company_id):\n",
    "    for k, l in enumerate(keyword_id):\n",
    "        if j == l:\n",
    "            company_mapping['keyword'][i] = keyword_mapping['keyword'][k]\n",
    "            company_mapping['keyword2'][i] = keyword_mapping['keyword2'][k]\n",
    "\n",
    "#company_mapping.to_csv('C:/projectnasdaq/project2/company_and_keyword.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## yahoo_dataset 파일 수정 ( yahoo_dataset_mapping.csv 에 저장 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# yahoo_dataset 파일 수정 ( -> symbol name 수정 )\n",
    "yahoo_dataset = pd.read_csv('C:/projectnasdaq/project2/yahoo_dataset.csv')\n",
    "yahoo_dataset.insert(1,'new_symbol','0')\n",
    "yahoo_dataset.insert(2,'name','0')\n",
    "yahoo_dataset.insert(3,'company_word','0')\n",
    "\n",
    "yahoo_dataset_symbol = yahoo_dataset['symbol']\n",
    "rep_stock_symbol = rep_stock['symbol']\n",
    "\n",
    "for i, j in enumerate(yahoo_dataset_symbol):\n",
    "    for k, l in enumerate(rep_stock_symbol):\n",
    "        if j == l:\n",
    "            yahoo_dataset['new_symbol'][i] = rep_stock['symbol'][k]\n",
    "            yahoo_dataset['name'][i] = rep_stock['name'][k]\n",
    "            yahoo_dataset['company_word'][i] = rep_stock['name_a'][k]\n",
    "            break\n",
    "\n",
    "# yahoo_dataset 컬럼 정리\n",
    "yahoo_dataset.drop(columns=[\"quoteType\", \"currency\", 'regularMarketPrice', 'regularMarketChange', 'regularMarketChangePercent',\n",
    "             'regularMarketVolume', 'averageDailyVolume3Month', 'marketCap', 'trailingPE', 'fiftyTwoWeekLow',\n",
    "             'fiftyTwoWeekHigh', 'regularMarketOpen', 'priceHint', 'underlyingSymbol'], inplace=True)\n",
    "yahoo_dataset.to_csv('C:/projectnasdaq/project2/yahoo_dataset_mapping.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 종목명이 추출된 뉴스 키워드들끼리 모으기 ( 딕셔너리 형태로 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# company단어들 하나씩만 list에 담기 -> 단어 이름이 같은 종목명들의 키워드 모으기 위해서\n",
    "company_and_keyword = pd.read_csv('C:/projectnasdaq/project2/company_and_keyword.csv')\n",
    "company_and_keyword.drop(columns=[\"Unnamed: 0\", 'Unnamed: 0.1'], inplace=True)\n",
    "company_word = company_and_keyword['company_word']\n",
    "\n",
    "company_word_same_list = []\n",
    "for company in company_word:\n",
    "    if company not in company_word_same_list:\n",
    "        company_word_same_list.append(company)\n",
    "\n",
    "company_word_sames = pd.DataFrame(company_word_same_list, columns=['company_word_same'])\n",
    "company_word_same = company_word_sames['company_word_same']\n",
    "\n",
    "# 키워드랑 company_name이랑 데이터프레임에서 맵핑 시키기위한 새로운 dataframe 생성\n",
    "company__name = pd.DataFrame(columns=['company', 'keyword', 'keyword2','key_list'])\n",
    "\n",
    "# 딕셔너리를 { news_id : keyword } 형태로 만들기 위해서 index를 news_id로 설정\n",
    "company_and_keyword = company_and_keyword.set_index(keys='news_id', drop=False, inplace=False)\n",
    "\n",
    "# company__name에 대한 키워드들 딕셔너리 형태로 모으기\n",
    "for i, j in enumerate(company_word_same):\n",
    "    company__name.loc[i] = [j, company_and_keyword[company_and_keyword['company_word'] == j]['keyword'].to_dict(), company_and_keyword[company_and_keyword['company_word'] == j]['keyword2'].to_dict(),company_and_keyword[company_and_keyword['company_word'] == j]['keyword'].tolist()] # 리스트 형태로 키워드만 뽑아오기 위해서"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "    symbol                                             name  \\\n0       KO                          Coca-Cola Company (The)   \n1       UL                                     Unilever PLC   \n2      DEO                                       Diageo plc   \n3      BUD  Anheuser-Busch Inbev SA Sponsored ADR (Belgium)   \n4     SBUX                            Starbucks Corporation   \n..     ...                                              ...   \n425    DAL                              Delta Air Lines Inc   \n426   GDRX                              GoodRx Holdings Inc   \n427    SPI                                    SPI Energy Co   \n428    PBR                            Petroleo Brasileiro S   \n429    BAK                                   Braskem SA ADR   \n\n                           shortName                              longName  \\\n0            Coca-Cola Company (The)                 The Coca-Cola Company   \n1                       Unilever PLC                          Unilever PLC   \n2                         Diageo plc                            Diageo plc   \n3    Anheuser-Busch Inbev SA Sponsor            Anheuser-Busch InBev SA/NV   \n4              Starbucks Corporation                 Starbucks Corporation   \n..                               ...                                   ...   \n425            Delta Air Lines, Inc.                 Delta Air Lines, Inc.   \n426            GoodRx Holdings, Inc.                 GoodRx Holdings, Inc.   \n427             SPI Energy Co., Ltd.                  SPI Energy Co., Ltd.   \n428  Petroleo Brasileiro S.A.- Petro  Petróleo Brasileiro S.A. - Petrobras   \n429                       Braskem SA                          Braskem S.A.   \n\n                 company                                       company_info  \\\n0              coca cola  {\"address1\": \"One Coca-Cola Plaza\", \"city\": \"A...   \n1               unilever  {\"address1\": \"Unilever House\", \"address2\": \"10...   \n2                 diageo  {\"address1\": \"Lakeside Drive\", \"address2\": \"Pa...   \n3         anheuser busch  {\"address1\": \"Brouwerijplein 1\", \"city\": \"Leuv...   \n4              starbucks  {\"address1\": \"2401 Utah Avenue South\", \"city\":...   \n..                   ...                                                ...   \n425            delta air  {\"address1\": \"PO Box 20706\", \"city\": \"Atlanta\"...   \n426      goodrx holdings  {\"address1\": \"2701 Olympic Boulevard\", \"addres...   \n427           spi energy  {\"address1\": \"4803 Urbani Avenue\", \"address2\":...   \n428  petroleo brasileiro  {\"address1\": \"Avenida RepUblica do Chile, 65\",...   \n429           braskem sa  {\"address1\": \"120, Rua Lemos Monteiro\", \"addre...   \n\n                                               keyword  \\\n0    {'345585': '['nestle', 'starbucks', 'brands', ...   \n1    {'345585': '['nestle', 'starbucks', 'brands', ...   \n2    {'345585': '['nestle', 'starbucks', 'brands', ...   \n3    {'345585': '['nestle', 'starbucks', 'brands', ...   \n4    {'345585': '['nestle', 'starbucks', 'brands', ...   \n..                                                 ...   \n425  {'443844': '['pandemic', 'airline', 'airlines'...   \n426  {'443702': '['recession', 'stocks', 'stocksthe...   \n427  {'443710': '['tesla', 'ev', 'spi', 'stocks', '...   \n428  {'443728': '['vitol', 'indictment', 'prosecuto...   \n429  {'443728': '['vitol', 'indictment', 'prosecuto...   \n\n                                              keyword2  \\\n0    {'345585': '['nestle sa', 'nestle', 'underperf...   \n1    {'345585': '['nestle sa', 'nestle', 'underperf...   \n2    {'345585': '['nestle sa', 'nestle', 'underperf...   \n3    {'345585': '['nestle sa', 'nestle', 'underperf...   \n4    {'345585': '['nestle sa', 'nestle', 'underperf...   \n..                                                 ...   \n425  {'443844': '['airline inevitable', 'pandemic c...   \n426  {'443702': '['rampant stock', ' stocks slumped...   \n427  {'443710': '['energy stocks', ' spi stock', 'i...   \n428  {'443728': '['bribes vitol', 'vitol firm', 'au...   \n429  {'443728': '['bribes vitol', 'vitol firm', 'au...   \n\n                                              key_list  \\\n0    [['nestle', 'starbucks', 'brands', 'bottled', ...   \n1    [['nestle', 'starbucks', 'brands', 'bottled', ...   \n2    [['nestle', 'starbucks', 'brands', 'bottled', ...   \n3    [['nestle', 'starbucks', 'brands', 'bottled', ...   \n4    [['nestle', 'starbucks', 'brands', 'bottled', ...   \n..                                                 ...   \n425  [['pandemic', 'airline', 'airlines', 'coronavi...   \n426  [['recession', 'stocks', 'stocksthe', 'markets...   \n427        [['tesla', 'ev', 'spi', 'stocks', 'stock']]   \n428  [['vitol', 'indictment', 'prosecutors', 'indic...   \n429  [['vitol', 'indictment', 'prosecutors', 'indic...   \n\n                                        frequency_word  \\\n0    [nestle, starbucks, brands, bottled, marketpos...   \n1    [nestle, starbucks, brands, bottled, marketpal...   \n2    [nestle, starbucks, brands, bottled, marketdia...   \n3    [nestle, starbucks, brands, bottled, marketinv...   \n4    [nestle, starbucks, brands, bottled, marketdis...   \n..                                                 ...   \n425  [pandemic, airline, airlines, coronavirus, fli...   \n426     [recession, stocks, stocksthe, markets, stock]   \n427                    [tesla, ev, spi, stocks, stock]   \n428  [vitol, indictment, prosecutors, indicted, pro...   \n429  [vitol, indictment, prosecutors, indicted, pro...   \n\n                                             frequency  \n0           [cola, nestle, starbucks, brands, bottled]  \n1     [nestle, starbucks, brands, bottled, marketpalm]  \n2    [nestle, starbucks, brands, bottled, marketdia...  \n3    [nestle, starbucks, brands, bottled, marketinv...  \n4       [starbucks, shenzhen, nestle, brands, bottled]  \n..                                                 ...  \n425  [pandemic, airline, airlines, coronavirus, fli...  \n426     [recession, stocks, stocksthe, markets, stock]  \n427                    [tesla, ev, spi, stocks, stock]  \n428  [vitol, indictment, prosecutors, indicted, pro...  \n429  [vitol, indictment, prosecutors, indicted, pro...  \n\n[430 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>symbol</th>\n      <th>name</th>\n      <th>shortName</th>\n      <th>longName</th>\n      <th>company</th>\n      <th>company_info</th>\n      <th>keyword</th>\n      <th>keyword2</th>\n      <th>key_list</th>\n      <th>frequency_word</th>\n      <th>frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KO</td>\n      <td>Coca-Cola Company (The)</td>\n      <td>Coca-Cola Company (The)</td>\n      <td>The Coca-Cola Company</td>\n      <td>coca cola</td>\n      <td>{\"address1\": \"One Coca-Cola Plaza\", \"city\": \"A...</td>\n      <td>{'345585': '['nestle', 'starbucks', 'brands', ...</td>\n      <td>{'345585': '['nestle sa', 'nestle', 'underperf...</td>\n      <td>[['nestle', 'starbucks', 'brands', 'bottled', ...</td>\n      <td>[nestle, starbucks, brands, bottled, marketpos...</td>\n      <td>[cola, nestle, starbucks, brands, bottled]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>UL</td>\n      <td>Unilever PLC</td>\n      <td>Unilever PLC</td>\n      <td>Unilever PLC</td>\n      <td>unilever</td>\n      <td>{\"address1\": \"Unilever House\", \"address2\": \"10...</td>\n      <td>{'345585': '['nestle', 'starbucks', 'brands', ...</td>\n      <td>{'345585': '['nestle sa', 'nestle', 'underperf...</td>\n      <td>[['nestle', 'starbucks', 'brands', 'bottled', ...</td>\n      <td>[nestle, starbucks, brands, bottled, marketpal...</td>\n      <td>[nestle, starbucks, brands, bottled, marketpalm]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DEO</td>\n      <td>Diageo plc</td>\n      <td>Diageo plc</td>\n      <td>Diageo plc</td>\n      <td>diageo</td>\n      <td>{\"address1\": \"Lakeside Drive\", \"address2\": \"Pa...</td>\n      <td>{'345585': '['nestle', 'starbucks', 'brands', ...</td>\n      <td>{'345585': '['nestle sa', 'nestle', 'underperf...</td>\n      <td>[['nestle', 'starbucks', 'brands', 'bottled', ...</td>\n      <td>[nestle, starbucks, brands, bottled, marketdia...</td>\n      <td>[nestle, starbucks, brands, bottled, marketdia...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BUD</td>\n      <td>Anheuser-Busch Inbev SA Sponsored ADR (Belgium)</td>\n      <td>Anheuser-Busch Inbev SA Sponsor</td>\n      <td>Anheuser-Busch InBev SA/NV</td>\n      <td>anheuser busch</td>\n      <td>{\"address1\": \"Brouwerijplein 1\", \"city\": \"Leuv...</td>\n      <td>{'345585': '['nestle', 'starbucks', 'brands', ...</td>\n      <td>{'345585': '['nestle sa', 'nestle', 'underperf...</td>\n      <td>[['nestle', 'starbucks', 'brands', 'bottled', ...</td>\n      <td>[nestle, starbucks, brands, bottled, marketinv...</td>\n      <td>[nestle, starbucks, brands, bottled, marketinv...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SBUX</td>\n      <td>Starbucks Corporation</td>\n      <td>Starbucks Corporation</td>\n      <td>Starbucks Corporation</td>\n      <td>starbucks</td>\n      <td>{\"address1\": \"2401 Utah Avenue South\", \"city\":...</td>\n      <td>{'345585': '['nestle', 'starbucks', 'brands', ...</td>\n      <td>{'345585': '['nestle sa', 'nestle', 'underperf...</td>\n      <td>[['nestle', 'starbucks', 'brands', 'bottled', ...</td>\n      <td>[nestle, starbucks, brands, bottled, marketdis...</td>\n      <td>[starbucks, shenzhen, nestle, brands, bottled]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>DAL</td>\n      <td>Delta Air Lines Inc</td>\n      <td>Delta Air Lines, Inc.</td>\n      <td>Delta Air Lines, Inc.</td>\n      <td>delta air</td>\n      <td>{\"address1\": \"PO Box 20706\", \"city\": \"Atlanta\"...</td>\n      <td>{'443844': '['pandemic', 'airline', 'airlines'...</td>\n      <td>{'443844': '['airline inevitable', 'pandemic c...</td>\n      <td>[['pandemic', 'airline', 'airlines', 'coronavi...</td>\n      <td>[pandemic, airline, airlines, coronavirus, fli...</td>\n      <td>[pandemic, airline, airlines, coronavirus, fli...</td>\n    </tr>\n    <tr>\n      <th>426</th>\n      <td>GDRX</td>\n      <td>GoodRx Holdings Inc</td>\n      <td>GoodRx Holdings, Inc.</td>\n      <td>GoodRx Holdings, Inc.</td>\n      <td>goodrx holdings</td>\n      <td>{\"address1\": \"2701 Olympic Boulevard\", \"addres...</td>\n      <td>{'443702': '['recession', 'stocks', 'stocksthe...</td>\n      <td>{'443702': '['rampant stock', ' stocks slumped...</td>\n      <td>[['recession', 'stocks', 'stocksthe', 'markets...</td>\n      <td>[recession, stocks, stocksthe, markets, stock]</td>\n      <td>[recession, stocks, stocksthe, markets, stock]</td>\n    </tr>\n    <tr>\n      <th>427</th>\n      <td>SPI</td>\n      <td>SPI Energy Co</td>\n      <td>SPI Energy Co., Ltd.</td>\n      <td>SPI Energy Co., Ltd.</td>\n      <td>spi energy</td>\n      <td>{\"address1\": \"4803 Urbani Avenue\", \"address2\":...</td>\n      <td>{'443710': '['tesla', 'ev', 'spi', 'stocks', '...</td>\n      <td>{'443710': '['energy stocks', ' spi stock', 'i...</td>\n      <td>[['tesla', 'ev', 'spi', 'stocks', 'stock']]</td>\n      <td>[tesla, ev, spi, stocks, stock]</td>\n      <td>[tesla, ev, spi, stocks, stock]</td>\n    </tr>\n    <tr>\n      <th>428</th>\n      <td>PBR</td>\n      <td>Petroleo Brasileiro S</td>\n      <td>Petroleo Brasileiro S.A.- Petro</td>\n      <td>Petróleo Brasileiro S.A. - Petrobras</td>\n      <td>petroleo brasileiro</td>\n      <td>{\"address1\": \"Avenida RepUblica do Chile, 65\",...</td>\n      <td>{'443728': '['vitol', 'indictment', 'prosecuto...</td>\n      <td>{'443728': '['bribes vitol', 'vitol firm', 'au...</td>\n      <td>[['vitol', 'indictment', 'prosecutors', 'indic...</td>\n      <td>[vitol, indictment, prosecutors, indicted, pro...</td>\n      <td>[vitol, indictment, prosecutors, indicted, pro...</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>BAK</td>\n      <td>Braskem SA ADR</td>\n      <td>Braskem SA</td>\n      <td>Braskem S.A.</td>\n      <td>braskem sa</td>\n      <td>{\"address1\": \"120, Rua Lemos Monteiro\", \"addre...</td>\n      <td>{'443728': '['vitol', 'indictment', 'prosecuto...</td>\n      <td>{'443728': '['bribes vitol', 'vitol firm', 'au...</td>\n      <td>[['vitol', 'indictment', 'prosecutors', 'indic...</td>\n      <td>[vitol, indictment, prosecutors, indicted, pro...</td>\n      <td>[vitol, indictment, prosecutors, indicted, pro...</td>\n    </tr>\n  </tbody>\n</table>\n<p>430 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company__name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## news_raw_dataset 만들기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# company__name.csv에 column 삽입\n",
    "company__name.insert(0, 'symbol','0')\n",
    "company__name.insert(1, 'name','0')\n",
    "company__name.insert(2, 'shortName','0')\n",
    "company__name.insert(3, 'longName','0')\n",
    "company__name.insert(5, 'company_info','0')\n",
    "\n",
    "yahoo_dataset_mapping = pd.read_csv('C:/projectnasdaq/project2/yahoo_dataset_mapping.csv')\n",
    "company_word = pd.read_csv('C:/projectnasdaq/project2/company_word.csv')\n",
    "\n",
    "# company__name.csv에 symbol, name 데이터 삽입\n",
    "company_word_ = company_word['company_word']\n",
    "company__ = company__name['company']\n",
    "\n",
    "for i,j in enumerate(company_word_):\n",
    "    for k, l in enumerate(company__):\n",
    "        if j==l:\n",
    "            company__name['symbol'][k] = company_word['symbol'][i]\n",
    "            company__name['name'][k] = company_word['name'][i]\n",
    "            break\n",
    "\n",
    "# company__name.csv에 yahoo finance 정보 수집 내용 삽입\n",
    "yahoo_dataset_mapping_symbol = yahoo_dataset_mapping['new_symbol']\n",
    "company__name_symbol = company__name['symbol']\n",
    "\n",
    "for i,j in enumerate(yahoo_dataset_mapping_symbol):\n",
    "    for k,l in enumerate(company__name_symbol):\n",
    "        if j==l:\n",
    "            company__name['shortName'][k] = yahoo_dataset_mapping['shortName'][i]\n",
    "            company__name['longName'][k] = yahoo_dataset_mapping['longName'][i]\n",
    "            company__name['company_info'][k] = yahoo_dataset_mapping['company_info'][i]\n",
    "            break\n",
    "\n",
    "# 완성된 news_raw dataset\n",
    "#company__name.to_csv('C:/projectnasdaq/project2/news_raw_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 대표 키워드 추출"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\q1035\\anaconda3\\envs\\intern_lv2\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 키워드 빈도수 순으로 정리해서 5개까지만 뽑아오기\n",
    "company__name['frequency_word'] = 0\n",
    "company__name['frequency'] = 0\n",
    "\n",
    "key_list_ = company__name['key_list']\n",
    "for i, j in enumerate(key_list_):\n",
    "        company__name['frequency_word'][i] = ''.join(j)\n",
    "\n",
    "company__name['frequency_word'].replace(['\\]','\\[','\\''],'',regex=True, inplace=True)\n",
    "company__name['frequency_word'].replace(',',' ',regex=True, inplace=True)\n",
    "company__name['frequency_word'] = company__name['frequency_word'].str.split(\" \")\n",
    "company__name['frequency_word'] = company__name['frequency_word'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])\n",
    "\n",
    "frequency_words = company__name['frequency_word']\n",
    "for i, j in enumerate(frequency_words):\n",
    "    # 대표 키워드 빈도순으로 5개 추출\n",
    "    company__name['frequency'][i] = Counter(j).most_common(5)\n",
    "\n",
    "# 다섯개 뽑아온 키워드 전처리\n",
    "company__name['frequency'] = company__name['frequency'].apply(lambda x: re.sub('[^a-zA-Z&]', ' ', str(x)).strip())\n",
    "company__name['frequency'] = company__name['frequency'].str.split(\" \")\n",
    "company__name['frequency'] = company__name['frequency'].apply(lambda x: [i for i in x if i != \"\" and i != \" \"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# 뉴스 원문에 대표 키워드가 포함될 경우 news_id와 symbol 맵핑\n",
    "frequency = company__name['frequency'] # 키워드 빈도수로 정렬 후 5개만 담아온 리스트\n",
    "news_stock_mapping = pd.DataFrame(columns=['news_id', 'symbol','name','summary','frequency'])\n",
    "\n",
    "a = 0\n",
    "for i, j in enumerate(tokenize_list):\n",
    "    for k,l in enumerate(frequency):\n",
    "        a = a + 1\n",
    "        #print(news_raw['news_id'][i])\n",
    "        together = set(j)&set(l)\n",
    "        # 뉴스 원문에 대표 키워드가 4개 이상 교집합으로 있을 경우\n",
    "        if len(together)==5:\n",
    "            news_stock_mapping.loc[a] = [news_raw['news_id'][i], company__name['symbol'][k], company__name['name'][k],                                                 news_raw['summary'][i], company__name['frequency'][k]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 맵핑 수 : 543\n"
     ]
    }
   ],
   "source": [
    "print('총 맵핑 수 :',len(news_stock_mapping))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "0             [cola, nestle, starbucks, brands, bottled]\n1       [nestle, starbucks, brands, bottled, marketpalm]\n2      [nestle, starbucks, brands, bottled, marketdia...\n3      [nestle, starbucks, brands, bottled, marketinv...\n4         [starbucks, shenzhen, nestle, brands, bottled]\n                             ...                        \n425    [pandemic, airline, airlines, coronavirus, fli...\n426       [recession, stocks, stocksthe, markets, stock]\n427                      [tesla, ev, spi, stocks, stock]\n428    [vitol, indictment, prosecutors, indicted, pro...\n429    [vitol, indictment, prosecutors, indicted, pro...\nName: frequency, Length: 430, dtype: object"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [news_id, symbol, name, summary, frequency, keyword_ten]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>news_id</th>\n      <th>symbol</th>\n      <th>name</th>\n      <th>summary</th>\n      <th>frequency</th>\n      <th>keyword_ten</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_stock_mapping_2 = pd.DataFrame(columns=['news_id', 'symbol','name','summary','frequency','keyword_ten'])\n",
    "news_stock_mapping_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "news_stock_mapping_2 = pd.DataFrame(columns=['news_id', 'symbol','name','summary','frequency','keyword_ten'])\n",
    "news_raw_keyword_ten = keyword_mapping['keyword_ten']\n",
    "# frequency => 종목명의 대표키워드\n",
    "a=0\n",
    "for i,j in enumerate(news_raw_keyword_ten):\n",
    "    for k,l in enumerate(frequency):\n",
    "        a=a+1\n",
    "        together = set(j)&set(l)\n",
    "        if len(together)>=4:\n",
    "            news_stock_mapping_2.loc[a] = [keyword_mapping['news_id'][i], company__name['symbol'][k], company__name['name'][k],                            keyword_mapping['summary'][i], company__name['frequency'][k],keyword_mapping['keyword_ten'][i]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "       news_id symbol                                             name  \\\n1       345585     KO                          Coca-Cola Company (The)   \n2       345585     UL                                     Unilever PLC   \n3       345585    DEO                                       Diageo plc   \n4       345585    BUD  Anheuser-Busch Inbev SA Sponsored ADR (Belgium)   \n5       345585   SBUX                            Starbucks Corporation   \n...        ...    ...                                              ...   \n423678  443710   TSLA                                        Tesla Inc   \n423861  443710   HOOD                            Robinhood Markets Inc   \n423978  443710    SPI                                    SPI Energy Co   \n426129  443728    PBR                            Petroleo Brasileiro S   \n426130  443728    BAK                                   Braskem SA ADR   \n\n                                                  summary  \\\n1            nestle sa sailed past ailing consumer goo...   \n2            nestle sa sailed past ailing consumer goo...   \n3            nestle sa sailed past ailing consumer goo...   \n4            nestle sa sailed past ailing consumer goo...   \n5            nestle sa sailed past ailing consumer goo...   \n...                                                   ...   \n423678       the hunt for renewable energy stocks sent...   \n423861       the hunt for renewable energy stocks sent...   \n423978       the hunt for renewable energy stocks sent...   \n426129       a former manager at vitol group  the worl...   \n426130       a former manager at vitol group  the worl...   \n\n                                                frequency  \\\n1              [cola, nestle, starbucks, brands, bottled]   \n2        [nestle, starbucks, brands, bottled, marketpalm]   \n3       [nestle, starbucks, brands, bottled, marketdia...   \n4       [nestle, starbucks, brands, bottled, marketinv...   \n5          [starbucks, shenzhen, nestle, brands, bottled]   \n...                                                   ...   \n423678              [stocks, tesla, ev, stock, stocksthe]   \n423861          [stocks, investors, tesla, stock, shares]   \n423978                    [tesla, ev, spi, stocks, stock]   \n426129  [vitol, indictment, prosecutors, indicted, pro...   \n426130  [vitol, indictment, prosecutors, indicted, pro...   \n\n                                              keyword_ten  \n1       [nestle, starbucks, brands, bottled, market, n...  \n2       [nestle, starbucks, brands, bottled, market, n...  \n3       [nestle, starbucks, brands, bottled, market, n...  \n4       [nestle, starbucks, brands, bottled, market, n...  \n5       [nestle, starbucks, brands, bottled, market, n...  \n...                                                   ...  \n423678  [tesla, ev, spi, stocks, stock, evs, edison, s...  \n423861  [tesla, ev, spi, stocks, stock, evs, edison, s...  \n423978  [tesla, ev, spi, stocks, stock, evs, edison, s...  \n426129  [vitol, indictment, prosecutors, indicted, pro...  \n426130  [vitol, indictment, prosecutors, indicted, pro...  \n\n[1069 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>news_id</th>\n      <th>symbol</th>\n      <th>name</th>\n      <th>summary</th>\n      <th>frequency</th>\n      <th>keyword_ten</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>345585</td>\n      <td>KO</td>\n      <td>Coca-Cola Company (The)</td>\n      <td>nestle sa sailed past ailing consumer goo...</td>\n      <td>[cola, nestle, starbucks, brands, bottled]</td>\n      <td>[nestle, starbucks, brands, bottled, market, n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>345585</td>\n      <td>UL</td>\n      <td>Unilever PLC</td>\n      <td>nestle sa sailed past ailing consumer goo...</td>\n      <td>[nestle, starbucks, brands, bottled, marketpalm]</td>\n      <td>[nestle, starbucks, brands, bottled, market, n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>345585</td>\n      <td>DEO</td>\n      <td>Diageo plc</td>\n      <td>nestle sa sailed past ailing consumer goo...</td>\n      <td>[nestle, starbucks, brands, bottled, marketdia...</td>\n      <td>[nestle, starbucks, brands, bottled, market, n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>345585</td>\n      <td>BUD</td>\n      <td>Anheuser-Busch Inbev SA Sponsored ADR (Belgium)</td>\n      <td>nestle sa sailed past ailing consumer goo...</td>\n      <td>[nestle, starbucks, brands, bottled, marketinv...</td>\n      <td>[nestle, starbucks, brands, bottled, market, n...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>345585</td>\n      <td>SBUX</td>\n      <td>Starbucks Corporation</td>\n      <td>nestle sa sailed past ailing consumer goo...</td>\n      <td>[starbucks, shenzhen, nestle, brands, bottled]</td>\n      <td>[nestle, starbucks, brands, bottled, market, n...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>423678</th>\n      <td>443710</td>\n      <td>TSLA</td>\n      <td>Tesla Inc</td>\n      <td>the hunt for renewable energy stocks sent...</td>\n      <td>[stocks, tesla, ev, stock, stocksthe]</td>\n      <td>[tesla, ev, spi, stocks, stock, evs, edison, s...</td>\n    </tr>\n    <tr>\n      <th>423861</th>\n      <td>443710</td>\n      <td>HOOD</td>\n      <td>Robinhood Markets Inc</td>\n      <td>the hunt for renewable energy stocks sent...</td>\n      <td>[stocks, investors, tesla, stock, shares]</td>\n      <td>[tesla, ev, spi, stocks, stock, evs, edison, s...</td>\n    </tr>\n    <tr>\n      <th>423978</th>\n      <td>443710</td>\n      <td>SPI</td>\n      <td>SPI Energy Co</td>\n      <td>the hunt for renewable energy stocks sent...</td>\n      <td>[tesla, ev, spi, stocks, stock]</td>\n      <td>[tesla, ev, spi, stocks, stock, evs, edison, s...</td>\n    </tr>\n    <tr>\n      <th>426129</th>\n      <td>443728</td>\n      <td>PBR</td>\n      <td>Petroleo Brasileiro S</td>\n      <td>a former manager at vitol group  the worl...</td>\n      <td>[vitol, indictment, prosecutors, indicted, pro...</td>\n      <td>[vitol, indictment, prosecutors, indicted, pro...</td>\n    </tr>\n    <tr>\n      <th>426130</th>\n      <td>443728</td>\n      <td>BAK</td>\n      <td>Braskem SA ADR</td>\n      <td>a former manager at vitol group  the worl...</td>\n      <td>[vitol, indictment, prosecutors, indicted, pro...</td>\n      <td>[vitol, indictment, prosecutors, indicted, pro...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1069 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_stock_mapping_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "3094"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_stock_mapping_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}